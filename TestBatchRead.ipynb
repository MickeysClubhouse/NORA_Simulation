{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import import_ipynb\n",
    "import time\n",
    "from numpy import genfromtxt\n",
    "import rtree\n",
    "from rtree import index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - 0 - - - \n",
      "load time:  0.7495675086975098\n",
      "- - - 1 - - - \n",
      "load time:  0.8139548301696777\n",
      "- - - 2 - - - \n",
      "load time:  0.855985164642334\n",
      "- - - 3 - - - \n",
      "load time:  0.9320805072784424\n",
      "- - - 4 - - - \n",
      "load time:  1.012078046798706\n",
      "- - - 5 - - - \n",
      "load time:  1.1780333518981934\n",
      "- - - 6 - - - \n",
      "load time:  1.167330026626587\n",
      "- - - 7 - - - \n",
      "load time:  1.2551357746124268\n",
      "- - - 8 - - - \n",
      "load time:  1.4044301509857178\n",
      "- - - 9 - - - \n",
      "load time:  1.4435057640075684\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100000\n",
    "TOTAL_SIZE = 100000\n",
    "for i in range(10):\n",
    "    s_time = time.time()\n",
    "    dataset = genfromtxt('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Legacy/data/TPCH_12M_8Field.csv', delimiter=',',\n",
    "                        skip_header = i*batch_size, max_rows = batch_size)\n",
    "    e_time = time.time()\n",
    "    print('- - -',i,'- - - ')\n",
    "    print('load time: ', e_time - s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conclusion: numpy method is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time:  1.2424235343933105\n",
      "1000000\n",
      "process time:  1.235649585723877\n",
      "1000000\n",
      "process time:  1.2551043033599854\n",
      "1000000\n",
      "process time:  1.2444002628326416\n",
      "1000000\n",
      "process time:  1.1985268592834473\n",
      "1000000\n",
      "process time:  1.1965761184692383\n",
      "1000000\n",
      "process time:  1.2083215713500977\n",
      "1000000\n",
      "process time:  1.1897449493408203\n",
      "1000000\n",
      "process time:  1.1985223293304443\n",
      "1000000\n",
      "process time:  1.1819350719451904\n",
      "1000000\n",
      "process time:  1.2297420501708984\n",
      "1000000\n",
      "process time:  1.2746565341949463\n",
      "997995\n"
     ]
    }
   ],
   "source": [
    "last_time = time.time()\n",
    "for chunk_df in pd.read_csv('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Legacy/data/TPCH_12M_8Field.csv', chunksize=1000000):\n",
    "    current_time = time.time()\n",
    "    print('process time: ',current_time - last_time)\n",
    "    print(len(chunk_df))\n",
    "    last_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conclusion: pandas method for chunk processing is acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total process time:  0.1064152717590332\n"
     ]
    }
   ],
   "source": [
    "# begin_time = time.time()\n",
    "\n",
    "# partition_path = 'D:/iCloudDrive/HUAWEI_LKD/HDFSExperiment/generated_partitions/nora_partitions'\n",
    "# partitions = load_partitions_from_file(partition_path)\n",
    "\n",
    "# p = index.Property()\n",
    "# p.leaf_capacity = 32 # cannot be less than 100, indicate the maximum capacity\n",
    "# p.index_capacity = 32\n",
    "# p.NearMinimumOverlapFactor = 16\n",
    "# p.fill_factor = 0.8\n",
    "# p.overwrite = True\n",
    "\n",
    "# pd_dict={}\n",
    "\n",
    "# # create index for the kdnodes\n",
    "# pidx = index.Index(properties = p) # Rtree index\n",
    "# for i in range(len(partitions)):\n",
    "#     #pidx.insert(partitions[i][-4], kdnode_2_border(partitions[i]))\n",
    "#     pidx.insert(i, kdnode_2_border(partitions[i]))\n",
    "    \n",
    "# end_time = time.time()   \n",
    "# print('total process time: ',end_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try batch read tbl format\n",
    "import pandas as pd\n",
    "\n",
    "def kdnode_2_border(kdnode):\n",
    "    lower = [domain[0] for domain in kdnode[0]]\n",
    "    upper = [domain[1] for domain in kdnode[0]]\n",
    "    border = tuple(lower + upper) # non interleave\n",
    "    return border\n",
    "\n",
    "table_path = 'D:/iCloudDrive/HUAWEI_LKD/9a84f6cd-727f-4f10-ae95-10a0214e10a4-tpc-h-tool/2.18.0_rc2/dbgen/lineitem.tbl'\n",
    "\n",
    "col_names = ['_c'+str(i) for i in range(16)] # using the last column as pid\n",
    "cols = [i for i in range(16)]\n",
    "\n",
    "partition_path = 'D:/iCloudDrive/HUAWEI_LKD/HDFSExperiment/generated_partitions/qd_tree_partitions'\n",
    "# partition_path = '~/PartitionLayout/qd_tree_partitions'\n",
    "partitions = load_partitions_from_file(partition_path)\n",
    "\n",
    "p = index.Property()\n",
    "p.leaf_capacity = 32 # cannot be less than 100, indicate the maximum capacity\n",
    "p.index_capacity = 32\n",
    "p.NearMinimumOverlapFactor = 16\n",
    "p.fill_factor = 0.8\n",
    "p.overwrite = True\n",
    "\n",
    "pd_dict={}\n",
    "\n",
    "# create index for the kdnodes\n",
    "pidx = index.Index(properties = p) # Rtree index\n",
    "for i in range(len(partitions)):\n",
    "    #pidx.insert(partitions[i][-4], kdnode_2_border(partitions[i]))\n",
    "    pidx.insert(i, kdnode_2_border(partitions[i]))\n",
    "    \n",
    "def find_pid(row, used_dims):\n",
    "    row_used_dims = row[used_dims]\n",
    "    #print('row_used_dims: ',row_used_dims)\n",
    "    row_list = row_used_dims.values.tolist()\n",
    "    #print('row_list: ', row_list)\n",
    "    border = tuple(row_list+row_list)\n",
    "    #print('border: ',border)\n",
    "    overlap_pid = list(pidx.intersection(border))\n",
    "    return overlap_pid[0]\n",
    "\n",
    "def find_pid2(row):\n",
    "    #print('row: ', row)\n",
    "    row_list = row.values.tolist()\n",
    "    border = tuple(row_list+row_list)\n",
    "    #print('border: ',border)\n",
    "    return list(pidx.intersection(border))[0]\n",
    "\n",
    "def find_pid3(row, used_dims):\n",
    "    row_used_dims = row[used_dims]\n",
    "    row_list = row_used_dims.values.tolist()\n",
    "    border = tuple(row_list+row_list)\n",
    "    pid = list(pidx.intersection(border))[0]\n",
    "    if pid in pd_dict:\n",
    "        pd_dict[pid].loc[len(pd_dict[pid])] = row.values.tolist() #pd_dict[pid].append(row, ignore_index=True)\n",
    "    else:\n",
    "        pd_dict.update({pid: pd.DataFrame(columns=col_names)})\n",
    "        pd_dict[pid].loc[0] = row.values.tolist()\n",
    "\n",
    "def find_pid4(row, used_dims):\n",
    "    row_used_dims = row[used_dims]\n",
    "    row_list = row_used_dims.values.tolist()\n",
    "    border = tuple(row_list+row_list)\n",
    "    pid = list(pidx.intersection(border))[0]\n",
    "    if pid in pd_dict:\n",
    "        pd_dict[pid].append(row.values.tolist())  #pd_dict[pid].append(row, ignore_index=True)\n",
    "    else:\n",
    "        pd_dict.update({pid: []})\n",
    "        pd_dict[pid].append(row.values.tolist())\n",
    "        \n",
    "def find_pid5(row, used_dims, pidx):\n",
    "    row_numpy = row.to_numpy()\n",
    "    row_list = row_numpy[used_dims].tolist()\n",
    "    border = tuple(row_list+row_list)\n",
    "    pid = list(pidx.intersection(border))[0]\n",
    "    if pid in pd_dict:\n",
    "        pd_dict[pid].append(row_numpy.tolist())  #pd_dict[pid].append(row, ignore_index=True)\n",
    "    else:\n",
    "        pd_dict.update({pid: []})\n",
    "        pd_dict[pid].append(row_numpy.tolist())\n",
    "        #print(pd_dict[pid])\n",
    "        \n",
    "def find_pid6(row, used_dims):\n",
    "    row_numpy = row.to_numpy()\n",
    "    row_list = row_numpy[used_dims].tolist()\n",
    "    border = tuple(row_list+row_list)\n",
    "    pid = list(pidx.intersection(border))[0]\n",
    "    if pid in pd_dict:\n",
    "        np.vstack((pd_dict[pid], row_numpy))  #pd_dict[pid].append(row, ignore_index=True)\n",
    "    else:\n",
    "        pd_dict.update({pid: row_numpy})\n",
    "        \n",
    "used_dims = [1,2]\n",
    "\n",
    "# begin_time = time.time()\n",
    "# last_time = time.time()\n",
    "\n",
    "# select_col_names = ['_c1','_c2']\n",
    "\n",
    "# count = 0\n",
    "# for chunk in pandas.read_table(table_path, delimiter='|', usecols=cols, names=col_names, chunksize=10):\n",
    "#     print('chunk id ', count)\n",
    "#     #print(chunk.iloc[:,used_dims])\n",
    "#     print(chunk[select_col_names])\n",
    "#     #chunk['pid'] = chunk.apply(lambda row: find_pid(row, used_dims), axis = 1) \n",
    "#     #chunk['pid'] = chunk.iloc[:,1:3].apply(find_pid2) the vectorization operation can only support 1 dimension\n",
    "#     count += 1\n",
    "#     current_time = time.time()\n",
    "#     print('chunk process time: ',current_time - last_time)\n",
    "#     last_time = current_time\n",
    "#     if count > 0:\n",
    "#         break\n",
    "        \n",
    "# end_time = time.time()   \n",
    "# print('total process time: ',end_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# begin_time = time.time()\n",
    "# pd_dict = {}\n",
    "# for i in range(1000):\n",
    "#     pd_dict.update({i:[]})\n",
    "# end_time = time.time()   \n",
    "# print('total process time: ',end_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pid_data_dict = {}\n",
    "for k in [9, 12, 16, 0, 36, 32, 1, 24, 20, 41, 28, 17, 44, 4, 52, 8, 48]:\n",
    "    pid_data_dict.update({k:[]})\n",
    "    \n",
    "def process_chunk_row(row, used_dims, pidx):\n",
    "    row_numpy = row.to_numpy()\n",
    "    row_used_dims_list = row_numpy[used_dims].tolist()\n",
    "    row_border = tuple(row_used_dims_list+row_used_dims_list)\n",
    "    pid = list(pidx.intersection(row_border))[0]\n",
    "    pid_data_dict[pid].append(row_numpy.tolist())\n",
    "#     if pid in pd_dict:\n",
    "#         pd_dict[pid].append(row_numpy.tolist())  #pd_dict[pid].append(row, ignore_index=True)\n",
    "#     else:\n",
    "#         pd_dict.update({pid: []})\n",
    "#         pd_dict[pid].append(row_numpy.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total process time:  3.4892258644104004\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "# 1.49 s ± 32.8 ms\n",
    "\n",
    "begin_time = time.time()\n",
    "\n",
    "count = 0\n",
    "for chunk in pandas.read_table(table_path, delimiter='|', usecols=cols, names=col_names, chunksize=100000):\n",
    "    #print('chunk id ', count)\n",
    "    # %lprun -f find_pid chunk.apply(lambda row: find_pid(row, used_dims), axis = 1)\n",
    "    #chunk['pid'] = chunk.apply(lambda row: find_pid(row, used_dims), axis = 1)\n",
    "    \n",
    "    #chunk.apply(lambda row: find_pid3(row, used_dims), axis = 1) # totally 44s for 1W rows\n",
    "    #%lprun -f find_pid3 chunk.apply(lambda row: find_pid3(row, used_dims), axis = 1)\n",
    "    \n",
    "    # chunk.apply(lambda row: find_pid4(row, used_dims), axis = 1)\n",
    "    #%lprun -f find_pid4 chunk.apply(lambda row: find_pid4(row, used_dims), axis = 1) \n",
    "    \n",
    "#     chunk.apply(lambda row: find_pid5(row, used_dims, pidx), axis = 1)\n",
    "#     chunk.apply(lambda row: find_pid6(row, used_dims), axis = 1)\n",
    "\n",
    "    chunk.apply(lambda row: process_chunk_row(row, used_dims, pidx), axis = 1)\n",
    "    \n",
    "    count += 1\n",
    "    if count > 0:\n",
    "        break \n",
    "        \n",
    "end_time = time.time()   \n",
    "print('total process time: ',end_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "dict_pid = {1:0, 2:0}\n",
    "\n",
    "class myThread(threading.Thread):\n",
    "    def __init__(self, tid, name, dict_pid, key, value):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.tid = tid\n",
    "        self.name = name\n",
    "        self.dict_pid = dict_pid\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        \n",
    "    def run(self):\n",
    "        self.dict_pid[self.key] += self.value\n",
    "\n",
    "thread1 = myThread(1, \"Thread-1\", dict_pid, 1, 2)\n",
    "thread2 = myThread(2, \"Thread-2\", dict_pid, 2, 2)\n",
    "thread3 = myThread(3, \"Thread-3\", dict_pid, 2, 1)\n",
    "thread4 = myThread(4, \"Thread-4\", dict_pid, 1, 3)\n",
    "\n",
    "\n",
    "# 开启新线程\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "thread4.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 5, 2: 3}\n"
     ]
    }
   ],
   "source": [
    "print(dict_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "refs:\n",
      "10000000\t<class 'list'> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2\n",
      "5696\t<class 'list'> ['# module pyparsing.py\\n', '#\\n', '# Copyright (c) 2003-2016  Paul T. McGuire\\n', '#\\n', '# Permiss\n",
      "3225\t<class 'list'> ['# -*- coding: utf-8 -*-\\n', '\"\"\"Main IPython class.\"\"\"\\n', '\\n', '#-------------------------------\n",
      "2576\t<class 'dict'> {2003551152: <weakref at 0x00000213B4CD4638; to 'type' at 0x00000000776BC3B0 (type)>, 2003554368: <w\n",
      "2028\t<class 'dict'> {'__name__': 'lib', '__doc__': None, '__package__': None, '__loader__': None, '__spec__': None, '_or\n",
      "2022\t<class 'dict'> {'Cryptography_HAS_CMS': 1, 'Cryptography_HAS_EC2M': 1, 'Cryptography_HAS_EC_1_0_2': 1, 'Cryptograph\n",
      "1280\t<class 'dict'> {'builtins': <module 'builtins' (built-in)>, 'sys': <module 'sys' (built-in)>, '_frozen_importlib': \n",
      "704\t<class 'dict'> {(<class 'str'>, '(-?(?:0|[1-9]\\\\d*))(\\\\.\\\\d+)?([eE][-+]?\\\\d+)?', <RegexFlag.VERBOSE|DOTALL|MULTILIN\n",
      "646\t<class 'set'> {'pytz-2017.2-py3.6.egg-info', 'mccabe.py', 'numpy-1.16.2.dist-info', 'branca', 'bkcharts', 'Rtree-0\n",
      "646\t<class 'set'> {'pytz-2017.2-py3.6.egg-info', 'mccabe.py', 'numpy-1.16.2.dist-info', 'branca', 'bkcharts', 'shapely\n",
      "\n",
      "bytes:\n",
      "81528056\t [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2\n",
      "73824\t {'__name__': 'lib', '__doc__': None, '__package__': None, '__loader__': None, '__spec__': None, '_or\n",
      "73824\t {'Cryptography_HAS_CMS': 1, 'Cryptography_HAS_EC2M': 1, 'Cryptography_HAS_EC_1_0_2': 1, 'Cryptograph\n",
      "45960\t ['# module pyparsing.py\\n', '#\\n', '# Copyright (c) 2003-2016  Paul T. McGuire\\n', '#\\n', '# Permiss\n",
      "36968\t {2003551152: <weakref at 0x00000213B4CD4638; to 'type' at 0x00000000776BC3B0 (type)>, 2003554368: <w\n",
      "36968\t {'builtins': <module 'builtins' (built-in)>, 'sys': <module 'sys' (built-in)>, '_frozen_importlib': \n",
      "33000\t LazySet({'Canada/East-Saskatchewan', 'Asia/Shanghai', 'Africa/Asmera', 'America/Argentina/San_Juan',\n",
      "33000\t LazySet({'Asia/Shanghai', 'America/Argentina/San_Juan', 'America/Kralendijk', 'America/Grenada', 'In\n",
      "32992\t {'ndindex', 'int_asbuffer', 'item', 'split', 'lexsort', 'byte_bounds', 'random_sample', 'inner', 'ff\n",
      "32992\t {'pytz-2017.2-py3.6.egg-info', 'mccabe.py', 'numpy-1.16.2.dist-info', 'branca', 'bkcharts', 'Rtree-0\n",
      "\n",
      "types:\n",
      "22042\t <class 'function'>\n",
      "13788\t <class 'dict'>\n",
      "11019\t <class 'tuple'>\n",
      "5927\t <class 'list'>\n",
      "5657\t <class 'weakref'>\n",
      "3210\t <class 'builtin_function_or_method'>\n",
      "3158\t <class 'getset_descriptor'>\n",
      "2976\t <class 'wrapper_descriptor'>\n",
      "2933\t <class 'type'>\n",
      "2619\t <class 'set'>\n",
      "\n",
      "\n",
      "refs:\n",
      "10000000\t<class 'list'> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2\n",
      "5696\t<class 'list'> ['# module pyparsing.py\\n', '#\\n', '# Copyright (c) 2003-2016  Paul T. McGuire\\n', '#\\n', '# Permiss\n",
      "3225\t<class 'list'> ['# -*- coding: utf-8 -*-\\n', '\"\"\"Main IPython class.\"\"\"\\n', '\\n', '#-------------------------------\n",
      "2576\t<class 'dict'> {2003551152: <weakref at 0x00000213B4CD4638; to 'type' at 0x00000000776BC3B0 (type)>, 2003554368: <w\n",
      "2028\t<class 'dict'> {'__name__': 'lib', '__doc__': None, '__package__': None, '__loader__': None, '__spec__': None, '_or\n",
      "2022\t<class 'dict'> {'Cryptography_HAS_CMS': 1, 'Cryptography_HAS_EC2M': 1, 'Cryptography_HAS_EC_1_0_2': 1, 'Cryptograph\n",
      "1280\t<class 'dict'> {'builtins': <module 'builtins' (built-in)>, 'sys': <module 'sys' (built-in)>, '_frozen_importlib': \n",
      "704\t<class 'dict'> {(<class 'str'>, '(-?(?:0|[1-9]\\\\d*))(\\\\.\\\\d+)?([eE][-+]?\\\\d+)?', <RegexFlag.VERBOSE|DOTALL|MULTILIN\n",
      "646\t<class 'set'> {'pytz-2017.2-py3.6.egg-info', 'mccabe.py', 'numpy-1.16.2.dist-info', 'branca', 'bkcharts', 'Rtree-0\n",
      "646\t<class 'set'> {'pytz-2017.2-py3.6.egg-info', 'mccabe.py', 'numpy-1.16.2.dist-info', 'branca', 'bkcharts', 'shapely\n",
      "\n",
      "bytes:\n",
      "81528056\t [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2\n",
      "73824\t {'__name__': 'lib', '__doc__': None, '__package__': None, '__loader__': None, '__spec__': None, '_or\n",
      "73824\t {'Cryptography_HAS_CMS': 1, 'Cryptography_HAS_EC2M': 1, 'Cryptography_HAS_EC_1_0_2': 1, 'Cryptograph\n",
      "45960\t ['# module pyparsing.py\\n', '#\\n', '# Copyright (c) 2003-2016  Paul T. McGuire\\n', '#\\n', '# Permiss\n",
      "36968\t {2003551152: <weakref at 0x00000213B4CD4638; to 'type' at 0x00000000776BC3B0 (type)>, 2003554368: <w\n",
      "36968\t {'builtins': <module 'builtins' (built-in)>, 'sys': <module 'sys' (built-in)>, '_frozen_importlib': \n",
      "33000\t LazySet({'Canada/East-Saskatchewan', 'Asia/Shanghai', 'Africa/Asmera', 'America/Argentina/San_Juan',\n",
      "33000\t LazySet({'Asia/Shanghai', 'America/Argentina/San_Juan', 'America/Kralendijk', 'America/Grenada', 'In\n",
      "32992\t {'ndindex', 'int_asbuffer', 'item', 'split', 'lexsort', 'byte_bounds', 'random_sample', 'inner', 'ff\n",
      "32992\t {'pytz-2017.2-py3.6.egg-info', 'mccabe.py', 'numpy-1.16.2.dist-info', 'branca', 'bkcharts', 'Rtree-0\n",
      "\n",
      "types:\n",
      "22040\t <class 'function'>\n",
      "13785\t <class 'dict'>\n",
      "11003\t <class 'tuple'>\n",
      "5922\t <class 'list'>\n",
      "5657\t <class 'weakref'>\n",
      "3207\t <class 'builtin_function_or_method'>\n",
      "3158\t <class 'getset_descriptor'>\n",
      "2976\t <class 'wrapper_descriptor'>\n",
      "2933\t <class 'type'>\n",
      "2619\t <class 'set'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mem_top import mem_top\n",
    "print(mem_top())\n",
    "test_arr = []\n",
    "for i in range(10000000):\n",
    "    test_arr.append(i)\n",
    "print(mem_top())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_MainThread(MainThread, started 134080)>,\n",
       " <Thread(Thread-4, started daemon 137280)>,\n",
       " <Heartbeat(Thread-5, started daemon 89848)>,\n",
       " <HistorySavingThread(IPythonHistorySavingThread, started 138684)>,\n",
       " <ParentPollerWindows(Thread-3, started daemon 35224)>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threading.enumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
