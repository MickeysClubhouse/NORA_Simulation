{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using a histogram to record the frequnetly query region\n",
    "# when split according to query, only query in the above region is considered\n",
    "# for other region, perform LKD? or KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import copy\n",
    "import rtree\n",
    "from rtree import index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assume hist is 2D\n",
    "def CreatePrefixSumHist(hist):\n",
    "    \n",
    "    # in case it's not in np\n",
    "    hist = np.array(hist)\n",
    "    \n",
    "    # accumulation in second dimension\n",
    "    for i in range(hist.shape[0]):\n",
    "        for j in range(1,hist.shape[1]):\n",
    "            hist[i,j] += hist[i,j-1]\n",
    "    \n",
    "    # now do the accumulation in first dimension\n",
    "    for j in range(hist.shape[1]):\n",
    "        for i in range(1,hist.shape[0]):\n",
    "            hist[i,j] += hist[i-1,j]\n",
    "            \n",
    "    return hist\n",
    "\n",
    "def CreatePrefixSumHist3D(hist):\n",
    "    \n",
    "    # in case it's not in np\n",
    "    hist = np.array(hist)\n",
    "    \n",
    "    # accumulation on the third dimension\n",
    "    for i in range(hist.shape[0]):\n",
    "        for j in range(hist.shape[1]):\n",
    "            for k in range(1,hist.shape[2]):\n",
    "                hist[i,j,k] += hist[i,j,k-1]\n",
    "    \n",
    "    # now do the accumulation on the second dimension\n",
    "    for k in range(hist.shape[2]):\n",
    "        for i in range(hist.shape[0]):\n",
    "            for j in range(1,hist.shape[1]):\n",
    "                hist[i,j,k] += hist[i,j-1,k]\n",
    "    \n",
    "    # now do the accumulation on the first dimension\n",
    "    for j in range(hist.shape[1]):\n",
    "        for k in range(hist.shape[2]):\n",
    "            for i in range(1,hist.shape[0]):\n",
    "                hist[i,j,k] += hist[i-1,j,k]\n",
    "            \n",
    "    return hist\n",
    "\n",
    "\n",
    "# def CreatePrefixSumHistND(hist):\n",
    "    \n",
    "#     # in case it's not in np\n",
    "#     hist = np.array(hist)\n",
    "#     shape_info = [shape for shape in hist.shape]\n",
    "#     for dim in range(len(hist.shape)):\n",
    "#     using recursion?\n",
    "\n",
    "# equal_width histogram, for 2D\n",
    "# query is in the form of kdnode[0], domain indicate the global domain, also in the form of kdnode[0]\n",
    "def QueryAccuHist(accu_hist, query, domain):\n",
    "    \n",
    "    bins = accu_hist.shape\n",
    "    \n",
    "    dim_1_lower_index = int((query[0][0]-domain[0][0])/(domain[0][1]-domain[0][0])*bins[0])\n",
    "    dim_1_upper_index = int((query[0][1]-domain[0][0])/(domain[0][1]-domain[0][0])*bins[0])\n",
    "    dim_2_lower_index = int((query[1][0]-domain[1][0])/(domain[1][1]-domain[0][0])*bins[1])\n",
    "    dim_2_upper_index = int((query[1][1]-domain[1][0])/(domain[1][1]-domain[0][0])*bins[1])\n",
    "    \n",
    "    if dim_1_lower_index >= bins[0]:\n",
    "        dim_1_lower_index = bins[0] - 1\n",
    "    \n",
    "    if dim_1_upper_index >= bins[0]:\n",
    "        dim_1_upper_index = bins[0] - 1\n",
    "        \n",
    "    if dim_2_lower_index >= bins[1]:\n",
    "        dim_2_lower_index = bins[1] - 1\n",
    "        \n",
    "    if dim_2_upper_index >= bins[1]:\n",
    "        dim_2_upper_index = bins[1] - 1\n",
    "    \n",
    "    d1L_d2L = accu_hist[dim_1_lower_index, dim_2_lower_index]\n",
    "    d1L_d2U = accu_hist[dim_1_lower_index, dim_2_upper_index]\n",
    "    d1U_d2L = accu_hist[dim_1_upper_index, dim_2_lower_index]\n",
    "    d1U_d2U = accu_hist[dim_1_upper_index, dim_2_upper_index]\n",
    "    \n",
    "    result = d1U_d2U - d1U_d2L - d1L_d2U + d1L_d2L\n",
    "    return result\n",
    "\n",
    "def generate_candidate_cut_pos(queryset):\n",
    "    '''\n",
    "    @parameter: queryset\n",
    "    @return: candiate cut position\n",
    "    '''\n",
    "    candidate_cut_pos = []\n",
    "    for i in range(len(queryset)):\n",
    "        for j in range(len(queryset[i])):\n",
    "            candidate_cut_pos.append((j, queryset[i][j][0]))\n",
    "            candidate_cut_pos.append((j, queryset[i][j][1]))      \n",
    "    return candidate_cut_pos\n",
    "\n",
    "def DatasetGenerator(queryset):\n",
    "    for i in range(len(queryset)):\n",
    "        lower = [domain[0] for domain in queryset[i]]\n",
    "        upper = [domain[1] for domain in queryset[i]]\n",
    "        border = tuple(lower + upper) # non interleave\n",
    "        yield(i, border, queryset[i])\n",
    "    return\n",
    "\n",
    "\n",
    "def skip_for_split(queryset, kdnode, idx):\n",
    "    count_skip = len(queryset) * kdnode[1]\n",
    "    lower = [domain[0] for domain in kdnode[0]]\n",
    "    upper = [domain[1] for domain in kdnode[0]]\n",
    "    for i in range(len(lower)):\n",
    "        if lower[i] >= upper[i]:\n",
    "            print(lower, upper)\n",
    "            print(kdnode)\n",
    "    border = tuple(lower + upper) # non interleave\n",
    "    overlapped_query_id = list(idx.intersection(border))low\n",
    "    count_skip -= kdnode[1] * len(overlapped_query_id)\n",
    "    return count_skip\n",
    "\n",
    "\n",
    "# this idx is index for query!!!\n",
    "def try_split(kdnode, candidate_cut, temp_dataset, queryset, idx, min_block_size):\n",
    "    split_dimension = candidate_cut[0]\n",
    "    split_value = candidate_cut[1]\n",
    "    \n",
    "    sub_dataset1 = temp_dataset[temp_dataset[:,split_dimension] <= split_value]\n",
    "    sub_dataset2 = temp_dataset[temp_dataset[:,split_dimension] > split_value]\n",
    "    #sub_dataset1 = temp_dataset  # used to test whether the above operation is too slow, and it is too slow!\n",
    "    #sub_dataset2 = temp_dataset\n",
    "\n",
    "    # check if the subnodes greater than threshold\n",
    "    sub_dataset1_size = len(sub_dataset1)\n",
    "    sub_dataset2_size = len(sub_dataset2)\n",
    "\n",
    "    if sub_dataset1_size < min_block_size or sub_dataset2_size < min_block_size:\n",
    "        return False, 0\n",
    "    \n",
    "    temp_sub_domains1 = np.copy(kdnode[0])\n",
    "    temp_sub_domains1[split_dimension][1] = split_value\n",
    "    temp_sub_domains2 = np.copy(kdnode[0])\n",
    "    temp_sub_domains2[split_dimension][0] = split_value\n",
    " \n",
    "    temp_sub_kdnodes_1 = [temp_sub_domains1, sub_dataset1_size]\n",
    "    temp_sub_kdnodes_2 = [temp_sub_domains2, sub_dataset2_size]\n",
    "    \n",
    "    if temp_sub_domains1[split_dimension][1] < temp_sub_domains1[split_dimension][0] or \\\n",
    "    temp_sub_domains2[split_dimension][0] > temp_sub_domains2[split_dimension][1]:\n",
    "        return False, 0\n",
    "    \n",
    "    count_skip = skip_for_split(queryset, temp_sub_kdnodes_1, idx) + skip_for_split(queryset, temp_sub_kdnodes_2, idx)\n",
    "    return True, count_skip\n",
    "\n",
    "\n",
    "def perform_split(i, kdnodes, max_skip_dim, max_skip_value, temp_dataset, dataset_dict, kdnode_dict, accu_count):\n",
    "    sub_domains1 = np.copy(kdnodes[i][0])\n",
    "    sub_domains1[max_skip_dim][1] = max_skip_value\n",
    "    sub_domains2 = np.copy(kdnodes[i][0])\n",
    "    sub_domains2[max_skip_dim][0] = max_skip_value\n",
    "\n",
    "    sub_dataset1 = temp_dataset[temp_dataset[:,max_skip_dim] <= max_skip_value]\n",
    "    sub_dataset2 = temp_dataset[temp_dataset[:,max_skip_dim] > max_skip_value]\n",
    "    sub_dataset1_size = len(sub_dataset1)\n",
    "    sub_dataset2_size = len(sub_dataset2)\n",
    "    \n",
    "    parent_node_id = kdnodes[i][-4]\n",
    "    sub_kdnodes_1 = [sub_domains1, sub_dataset1_size, accu_count + 1, parent_node_id, -1, -1]\n",
    "    sub_kdnodes_2 = [sub_domains2, sub_dataset2_size, accu_count + 2, parent_node_id, -1, -1]\n",
    "    \n",
    "    kdnode_dict[parent_node_id][-2] = accu_count + 1\n",
    "    kdnode_dict[parent_node_id][-1] = accu_count + 2\n",
    "    #kdnode_dict.update({accu_count + 1: copy.deepcopy(sub_kdnodes_1)}) \n",
    "    #kdnode_dict.update({accu_count + 2: copy.deepcopy(sub_kdnodes_2)}) \n",
    "    kdnode_dict.update({accu_count + 1: sub_kdnodes_1}) \n",
    "    kdnode_dict.update({accu_count + 2: sub_kdnodes_2}) \n",
    "\n",
    "    kdnodes[i] = sub_kdnodes_1\n",
    "    dataset_dict.update({i:sub_dataset1}) # one put in the original place\n",
    "    kdnodes.append(sub_kdnodes_2)\n",
    "    dataset_dict.update({len(kdnodes)-1:sub_dataset2}) # the other put in the end\n",
    "    \n",
    "# this idx is index for query!!!\n",
    "def try_split_approximate(kdnode, candidate_cut, dataset, queryset, idx, min_block_size, accu_hist, domain):\n",
    "    split_dimension = candidate_cut[0]\n",
    "    split_value = candidate_cut[1]\n",
    "    \n",
    "    temp_sub_domains1 = np.copy(kdnode[0])\n",
    "    temp_sub_domains1[split_dimension][1] = split_value\n",
    "    temp_sub_domains2 = np.copy(kdnode[0])\n",
    "    temp_sub_domains2[split_dimension][0] = split_value\n",
    "    \n",
    "    if temp_sub_domains1[split_dimension][1] < temp_sub_domains1[split_dimension][0] or \\\n",
    "    temp_sub_domains2[split_dimension][0] > temp_sub_domains2[split_dimension][1]:\n",
    "        return False, 0\n",
    "    \n",
    "    # check if the subnodes greater than threshold\n",
    "    sub_dataset1_size = QueryAccuHist(accu_hist, temp_sub_domains1, domain)\n",
    "    sub_dataset2_size = QueryAccuHist(accu_hist, temp_sub_domains2, domain)\n",
    "\n",
    "    if sub_dataset1_size < min_block_size or sub_dataset2_size < min_block_size:\n",
    "        return False, 0\n",
    "    \n",
    "    temp_sub_kdnodes_1 = [temp_sub_domains1, sub_dataset1_size]\n",
    "    temp_sub_kdnodes_2 = [temp_sub_domains2, sub_dataset2_size]\n",
    "    \n",
    "    count_skip = skip_for_split(queryset, temp_sub_kdnodes_1, idx) + skip_for_split(queryset, temp_sub_kdnodes_2, idx)\n",
    "    return True, count_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maybe we could use Rtree to indicate the number of queries in a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kdnode_2_border(kdnode):\n",
    "    lower = [domain[0] for domain in kdnode[0]]\n",
    "    upper = [domain[1] for domain in kdnode[0]]\n",
    "    border = tuple(lower + upper) # non interleave\n",
    "    return border\n",
    "\n",
    "def query_2_border(query):\n",
    "    lower = [domain[0] for domain in query]\n",
    "    upper = [domain[1] for domain in query]\n",
    "    border = tuple(lower + upper) # non interleave\n",
    "    return border\n",
    "\n",
    "def GetEmptyHist(m, n):\n",
    "    hist = []\n",
    "    for i in range(m):\n",
    "        hist.append([])\n",
    "        for j in range(n):\n",
    "            hist[i].append([0,set()])\n",
    "    return hist\n",
    "\n",
    "def InserQueryIntoHist(index, SingleQuery, hist, domain, m, n, threshold):\n",
    "\n",
    "    dim1_step = (domain[0][1]-domain[0][0])/m\n",
    "    dim2_step = (domain[1][1]-domain[1][0])/n\n",
    "    \n",
    "    dim1_index_min = int((SingleQuery[0][0] - domain[0][0]) / dim1_step)\n",
    "    dim1_index_max = int((SingleQuery[0][1] - domain[0][0]) / dim1_step)\n",
    "    dim2_index_min = int((SingleQuery[1][0] - domain[1][0]) / dim1_step)\n",
    "    dim2_index_max = int((SingleQuery[1][1] - domain[1][0]) / dim1_step)\n",
    "    \n",
    "    if dim1_index_min >= m:\n",
    "        dim1_index_min = m-1\n",
    "    if dim1_index_max >= m:\n",
    "        dim1_index_max = m-1\n",
    "    if dim2_index_min >= n:\n",
    "        dim2_index_min = n-1\n",
    "    if dim2_index_max >= n:\n",
    "        dim2_index_max = n-1\n",
    "        \n",
    "    distribution_regions = []\n",
    "    for m in range(dim1_index_min, dim1_index_max+1):\n",
    "        for n in range(dim2_index_min, dim2_index_max+1):\n",
    "            hist[m][n][0] += 1\n",
    "            hist[m][n][1].add(index)\n",
    "            if hist[m][n][0]-1 < threshold and hist[m][n][0] >= threshold: # whether a region just become distribution query region\n",
    "                distribution_regions.append((m,n))\n",
    "            \n",
    "    return distribution_regions\n",
    "            \n",
    "    # also need to check whether a region just become a distribution query region\n",
    "            \n",
    "def RemoveQueryFromHist(index, SingleQuery, hist, domain, m, n, threshold):\n",
    "    \n",
    "    dim1_step = (domain[0][1]-domain[0][0])/m\n",
    "    dim2_step = (domain[1][1]-domain[1][0])/n\n",
    "    \n",
    "    dim1_index_min = int((SingleQuery[0][0] - domain[0][0]) / dim1_step)\n",
    "    dim1_index_max = int((SingleQuery[0][1] - domain[0][0]) / dim1_step)\n",
    "    dim2_index_min = int((SingleQuery[1][0] - domain[1][0]) / dim1_step)\n",
    "    dim2_index_max = int((SingleQuery[1][1] - domain[1][0]) / dim1_step)\n",
    "    \n",
    "    if dim1_index_min >= m:\n",
    "        dim1_index_min = m-1\n",
    "    if dim1_index_max >= m:\n",
    "        dim1_index_max = m-1\n",
    "    if dim2_index_min >= n:\n",
    "        dim2_index_min = n-1\n",
    "    if dim2_index_max >= n:\n",
    "        dim2_index_max = n-1\n",
    "            \n",
    "    random_regions = []\n",
    "    for m in range(dim1_index_min, dim1_index_max+1):\n",
    "        for n in range(dim2_index_min, dim2_index_max+1):\n",
    "            hist[m][n][0] -= 1\n",
    "            hist[m][n][1].remove(index)\n",
    "            if hist[m][n][0] < threshold and hist[m][n][0] + 1 >= threshold: # consider whether a region just become random query region\n",
    "                random_regions.append((m,n))\n",
    "            \n",
    "    return random_regions\n",
    "        \n",
    "\n",
    "# need to properly determine wheter m and n and threshold\n",
    "# perform binary search on this? to maximize the differen?\n",
    "# using DBSCAN related methods?\n",
    "def filter_distribution_query(fusion_queryset, domains, m, n, threshold):\n",
    "    \n",
    "    fusion_queryset = np.array(fusion_queryset)\n",
    "    \n",
    "    queryset_hist = GetEmptyHist(m, n)\n",
    "    for i in range(len(fusion_queryset)):\n",
    "        InserQueryIntoHist(i, fusion_queryset[i], queryset_hist, domains, m, n, threshold)\n",
    "        \n",
    "    filtered_distribution_query_index = []\n",
    "        \n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if queryset_hist[i][j][0] >= threshold:\n",
    "                filtered_distribution_query_index += queryset_hist[i][j][1]\n",
    "            \n",
    "    filtered_distribution_query_index = set(filtered_distribution_query_index)\n",
    "    filtered_distribution_query_index = list(filtered_distribution_query_index)\n",
    "    distribution_query = fusion_queryset[filtered_distribution_query_index]\n",
    "    \n",
    "    return distribution_query, queryset_hist\n",
    "\n",
    "# only retrieve the leaf nodes\n",
    "def find_all_leafnode_ids(initial_id, kdnode_dict):\n",
    "    if kdnode_dict[initial_id][-1] == -1: # leaf node, has no child\n",
    "        return [initial_id]\n",
    "    else:\n",
    "        kid1 = kdnode_dict[initial_id][-2]\n",
    "        kid2 = kdnode_dict[initial_id][-1]\n",
    "        return find_all_leafnode_ids(kid1, kdnode_dict) + find_all_leafnode_ids(kid2, kdnode_dict)\n",
    "\n",
    "def find_all_subnode_ids(initial_id, kdnode_dict):\n",
    "    if kdnode_dict[initial_id][-1] == -1: # leaf node, has no child\n",
    "        return [initial_id]\n",
    "    else:\n",
    "        kid1 = kdnode_dict[initial_id][-2]\n",
    "        kid2 = kdnode_dict[initial_id][-1]\n",
    "        return [initial_id] + find_all_subnode_ids(kid1, kdnode_dict) + find_all_subnode_ids(kid2, kdnode_dict)\n",
    "\n",
    "def find_subset(dataset, domain):\n",
    "    constraints = []\n",
    "    for i in range(len(domain)):\n",
    "        constraint_1 = dataset[:,i] >= domain[i][0]\n",
    "        constraint_2 = dataset[:,i] < domain[i][1]\n",
    "        constraints.append(constraint_1)\n",
    "        constraints.append(constraint_2)\n",
    "    constraint = np.all(constraints, axis=0)\n",
    "    return dataset[constraint]\n",
    "    \n",
    "# we should index kdnodes by Rtree first (after initialization)\n",
    "# after a region just become random region\n",
    "def repartition_for_robustness(hist_indexes, m, n, dataset, domain, d_threshold, q_threshold, kdnode_idx, query_idx, \n",
    "                               kdnode_dict, accu_count_list):\n",
    "    \n",
    "    dim1_step = (domain[0][1]-domain[0][0])/m\n",
    "    dim2_step = (domain[1][1]-domain[1][0])/n\n",
    "    \n",
    "    kdnode_ids = []\n",
    "    \n",
    "    # first, find out all the overlap kdnodes\n",
    "    for i in range(len(hist_indexes)):\n",
    "        d1_lower = dim1_step * hist_indexes[i][0]\n",
    "        d1_upper = dim1_step * (hist_indexes[i][0]+1)\n",
    "        d2_lower = dim2_step * hist_indexes[i][1]\n",
    "        d2_upper = dim2_step * (hist_indexes[i][1]+1)\n",
    "    \n",
    "        # find the kdnode in this region\n",
    "        border = (d1_lower, d2_lower, d1_upper, d2_upper)\n",
    "        overlapped_kdnode_id = list(kdnode_idx.intersection(border))\n",
    "        kdnode_ids += overlapped_kdnode_id\n",
    "        \n",
    "    kdnode_ids = set(kdnode_ids)\n",
    "    \n",
    "    # second, try to process them\n",
    "    while len(kdnode_ids) > 0:\n",
    "        kid = kdnode_ids.pop()\n",
    "        kid_node = kdnode_dict[kid]\n",
    "        while True:\n",
    "            pid = kid_node[-3]\n",
    "            parent_kdnode = kdnode_dict[pid]    \n",
    "            parent_border = (parent_kdnode[0][0][0], parent_kdnode[0][1][0], parent_kdnode[0][0][1], parent_kdnode[0][1][1])\n",
    "            overlapped_query_id = list(query_idx.intersection(parent_border))\n",
    "            if len(overlapped_query_id) >= q_threshold:\n",
    "                break\n",
    "            else:\n",
    "                kid_node = parent_kdnode\n",
    "                if parent_kdnode[-3] == -1:\n",
    "                    break\n",
    "        \n",
    "        # remove all the sub kdnode ids under this region from the set, only leaf nodes should be considered\n",
    "        to_delete_leafnode_ids = find_all_leafnode_ids(kid_node[-4], kdnode_dict)\n",
    "        to_delete_leafnode_ids = set(to_delete_leafnode_ids)\n",
    "        kdnode_ids -= to_delete_leafnode_ids\n",
    "        \n",
    "        if kid_node[-5] < 2*d_threshold:\n",
    "            continue\n",
    "        \n",
    "        # remove the deleted kdnodes from kdnode_dict, including all the intermediate nodes\n",
    "        to_delete_subnode_ids = find_all_subnode_ids(kid_node[-4], kdnode_dict)\n",
    "        to_delete_subnode_ids.remove(kid_node[-4]) # keep the root\n",
    "        \n",
    "        \n",
    "        # repartition this region (kid_node) with KDT\n",
    "        temp_dataset = find_subset(dataset, kid_node[0])\n",
    "\n",
    "        #processed_kdnodes = TraditionalKDTree(temp_dataset, 0, kid_node[0], d_threshold, 0, kdnode_dict, accu_count_list, kid_node[-4])\n",
    "        processed_kdnodes = KDPartition(temp_dataset, 0, d_threshold, kid_node, kdnode_dict, accu_count_list)\n",
    "        \n",
    "        # process kdnode_idx, remove the deleted leaf nodes\n",
    "        for node_id in to_delete_leafnode_ids:\n",
    "            l1 = kdnode_dict[node_id][0][0][0]\n",
    "            l2 = kdnode_dict[node_id][0][1][0]\n",
    "            u1 = kdnode_dict[node_id][0][0][1]\n",
    "            u2 = kdnode_dict[node_id][0][1][1]\n",
    "            kdnode_idx.delete(node_id, (l1,l2,u1,u2))\n",
    "        \n",
    "        for node_id in to_delete_subnode_ids:\n",
    "            del kdnode_dict[node_id]\n",
    "        \n",
    "        # process kdnode_idx, add the newly created leaf nodes\n",
    "        for node in processed_kdnodes:\n",
    "            kdnode_idx.insert(node[2], (node[0][0][0], node[0][1][0], node[0][0][1],node[0][1][1]), node)\n",
    "        \n",
    "        \n",
    "# after a region just become distribution region\n",
    "def repartition_for_adaptation(total_queryset, hist_indexes, m, n, dataset, domain, d_threshold, q_threshold, kdnode_idx, query_idx, \n",
    "                               kdnode_dict, accu_count_list):\n",
    "    \n",
    "    dim1_step = (domain[0][1]-domain[0][0])/m\n",
    "    dim2_step = (domain[1][1]-domain[1][0])/n\n",
    "    \n",
    "    kdnode_ids = []\n",
    "    \n",
    "    # first, find out all the overlap kdnodes\n",
    "    for i in range(len(hist_indexes)):\n",
    "        d1_lower = dim1_step * hist_indexes[i][0]\n",
    "        d1_upper = dim1_step * (hist_indexes[i][0]+1)\n",
    "        d2_lower = dim2_step * hist_indexes[i][1]\n",
    "        d2_upper = dim2_step * (hist_indexes[i][1]+1)\n",
    "    \n",
    "        # find the kdnode in this region\n",
    "        border = (d1_lower, d2_lower, d1_upper, d2_upper)\n",
    "        overlapped_kdnode_id = list(kdnode_idx.intersection(border))\n",
    "        kdnode_ids += overlapped_kdnode_id\n",
    "        \n",
    "    kdnode_ids = set(kdnode_ids) # the leaf kdnodes to repartition\n",
    "    \n",
    "    while len(kdnode_ids) > 0:\n",
    "        kid = kdnode_ids.pop()\n",
    "        kid_node = kdnode_dict[kid]\n",
    "        parent_node = None\n",
    "        \n",
    "        while True:\n",
    "            pid = kid_node[-3]\n",
    "            parent_node = kdnode_dict[pid]\n",
    "            another_child_id = parent_node[-2]\n",
    "            if another_child_id == kid_node[-4]:\n",
    "                another_child_id = parent_node[-1]\n",
    "            \n",
    "            if another_child_id == -1:\n",
    "                break\n",
    "            \n",
    "            another_child_node = kdnode_dict[another_child_id]\n",
    "            another_child_border = (another_child_node [0][0][0], another_child_node [0][1][0], \n",
    "                                    another_child_node [0][0][1], another_child_node [0][1][1])      \n",
    "            \n",
    "            overlapped_query_id = list(query_idx.intersection(another_child_border))\n",
    "            if len(overlapped_query_id) < q_threshold or parent_node[-3] == -1:\n",
    "                break\n",
    "            else:\n",
    "                kid_node = parent_node\n",
    "        \n",
    "        # remove all the sub kdnode ids under this region from the set, only leaf nodes should be considered\n",
    "        to_delete_leafnode_ids = find_all_leafnode_ids(parent_node[-4], kdnode_dict) # delete the parent's subnodes!!! instead of kid's\n",
    "        to_delete_leafnode_ids = set(to_delete_leafnode_ids)\n",
    "        kdnode_ids -= to_delete_leafnode_ids\n",
    "        \n",
    "        if parent_node[-5] < 2*d_threshold:\n",
    "            continue\n",
    "    \n",
    "        # remove the deleted kdnodes from kdnode_dict, including all the intermediate nodes\n",
    "        to_delete_subnode_ids = find_all_subnode_ids(parent_node[-4], kdnode_dict)\n",
    "        to_delete_subnode_ids.remove(parent_node[-4]) # keep the root\n",
    "            \n",
    "        temp_dataset = find_subset(dataset, parent_node[0])\n",
    "        \n",
    "        # fileter queries only within the parent kdnode's domain \n",
    "        filtered_queryset_ids = list(query_idx.intersection(kdnode_2_border(parent_node)))\n",
    "        filtered_queryset = total_queryset[filtered_queryset_ids] # total_queryset should be in the form of numpy\n",
    "        #print('filtered_queryset size: ', len(filtered_queryset))\n",
    "        if len(filtered_queryset) == 0:\n",
    "            continue\n",
    "            \n",
    "        processed_kdnodes = LKD_Robust(temp_dataset, filtered_queryset, parent_node[0], d_threshold, (m,n), \n",
    "                                                   accu_count_list, kdnode_dict, parent_node)\n",
    "        \n",
    "        # perform KDT partition for the nodes generated by Qd-Tree methods\n",
    "        processed_kdnodes = post_kdnode_partition(processed_kdnodes, d_threshold, dataset, kdnode_dict, accu_count_list)\n",
    "        \n",
    " \n",
    "        # process kdnode_idx, remove the deleted leaf nodes\n",
    "        for node_id in to_delete_leafnode_ids:\n",
    "            l1 = kdnode_dict[node_id][0][0][0]\n",
    "            l2 = kdnode_dict[node_id][0][1][0]\n",
    "            u1 = kdnode_dict[node_id][0][0][1]\n",
    "            u2 = kdnode_dict[node_id][0][1][1]\n",
    "            kdnode_idx.delete(node_id, (l1,l2,u1,u2))\n",
    "        \n",
    "        for node_id in to_delete_subnode_ids:\n",
    "            del kdnode_dict[node_id]\n",
    "        \n",
    "        # process kdnode_idx, add the newly created leaf nodes\n",
    "        for node in processed_kdnodes:\n",
    "            kdnode_idx.insert(node[2], (node[0][0][0], node[0][1][0], node[0][0][1],node[0][1][1]), node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # = = = Unit Test = = =\n",
    "# # test for repartition_for_robustness and repartition_for_adaptation\n",
    "\n",
    "# # for incremental robustness\n",
    "# tiny_dataset = []\n",
    "# for i in range(11):\n",
    "#     for j in range(11):\n",
    "#         tiny_dataset.append([i,j])\n",
    "# tiny_dataset = np.array(tiny_dataset)\n",
    "\n",
    "# tiny_query_set = [ [[1,3.5],[1,3.5]], [[3,6],[5,8]], [[7,8],[3,6]] ]\n",
    "# tiny_block_size = 10\n",
    "# tiny_domains = [[0,10],[0,10]]\n",
    "\n",
    "# accu = [0]\n",
    "# kdict = {}\n",
    "# root_node = [tiny_domains,121,0,-1,-1,-1]\n",
    "\n",
    "# tiny_qdtree_kdnodes = LKD_Robust(tiny_dataset, tiny_query_set, tiny_domains, tiny_block_size,(10,10), accu, kdict, root_node)\n",
    "# print('kdict: ', kdict)\n",
    "# processed_kdnodes = post_kdnode_partition(tiny_qdtree_kdnodes, 5, tiny_dataset, kdict, accu)\n",
    "\n",
    "# p = index.Property()\n",
    "# p.leaf_capacity = 100 # cannot be less than 100, indicate the maximum capacity\n",
    "# p.fill_factor = 0.5\n",
    "# p.overwrite = True\n",
    "\n",
    "# # create index for the kdnodes\n",
    "# kidx = index.Index(properties = p) # Rtree index\n",
    "# for i in range(len(processed_kdnodes)):\n",
    "#     kidx.insert(processed_kdnodes[i][-4], kdnode_2_border(processed_kdnodes[i]), processed_kdnodes[i])\n",
    "                \n",
    "# qidx = index.Index(properties = p) # Rtree index\n",
    "# for i in range(len(tiny_query_set)):\n",
    "#     qidx.insert(i, (tiny_query_set[i][0][0],tiny_query_set[i][1][0],tiny_query_set[i][0][1],tiny_query_set[i][1][1]), tiny_query_set[i])\n",
    "    \n",
    "# # create query_hist\n",
    "# m, n = 10, 10\n",
    "# hist = GetEmptyHist(m, n)\n",
    "# InserQueryIntoHist(0, tiny_query_set[0], hist, tiny_domains, m, n, 1)\n",
    "# InserQueryIntoHist(1, tiny_query_set[1], hist, tiny_domains, m, n, 1)\n",
    "\n",
    "# print('before delete:')\n",
    "# print(kdict)\n",
    "# print('accu: ',accu)\n",
    "\n",
    "# print('= = =')\n",
    "# print('after delete:')\n",
    "# # delete query\n",
    "# hist_region_index = RemoveQueryFromHist(0, tiny_query_set[0], hist, tiny_domains, m, n, 1)\n",
    "# print('hist_region_index: ',hist_region_index)\n",
    "# repartition_for_robustness(hist_region_index, m, n, tiny_dataset, tiny_domains, 3, 1, kidx, qidx, kdict, accu)\n",
    "\n",
    "# print(kdict)\n",
    "# print('accu: ',accu)\n",
    "\n",
    "# print('= = =')\n",
    "# print('after insert:')\n",
    "# # insert query\n",
    "# continous_query = [ [[2,4],[2,4]] ]\n",
    "# total_query = tiny_query_set + continous_query\n",
    "# total_query = np.array(total_query)\n",
    "\n",
    "# hist_region_index = InserQueryIntoHist(3, total_query[3], hist, tiny_domains, m, n, 1)\n",
    "# repartition_for_adaptation(total_query, hist_region_index, m, n, tiny_dataset, tiny_domains, 3, 1, kidx, qidx, kdict, accu)\n",
    "# print(kdict)\n",
    "# print(accu)\n",
    "# print(qidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAD8CAYAAAC7IukgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZll5+RiZmbZObmYmVl2/x+cCS3iGN8UeQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from QueryGeneration import *\n",
    "# random_query = load_query('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Robust/query/random.csv')\n",
    "# distribution_query = load_query('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Robust/query/distribution.csv')\n",
    "# fusion_query = load_query('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Robust/query/fusion.csv')\n",
    "\n",
    "# domains_ = [[1,4.00000000e+05],[1,2.00000000e+04]]\n",
    "# domains_ = np.asarray(domains_)\n",
    "# # plot_queries_2d(fusion_query, domains_)\n",
    "# plot_queries_2d(distribution_query, domains_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAD8CAYAAAC7IukgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAcyfnyACTOIvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtered_distribution_query = filter_distribution_query(fusion_query, domains_, 1000, 1000, 2)\n",
    "# plot_queries_2d(filtered_distribution_query, domains_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notice: this will update the root_node in dict\n",
    "# the queryset here should be the queries that believed to be those follow some distribution\n",
    "def LKD_Robust(dataset, queryset, domains, min_block_size, bins, accu_count_list, kdnode_dict, root_node):\n",
    "    \n",
    "    root_node[-1] = -1\n",
    "    root_node[-2] = -1\n",
    "    kdnodes = [root_node]\n",
    "    \n",
    "    candidate_cut_pos = generate_candidate_cut_pos(queryset)\n",
    "    \n",
    "    dataset_dict = {} # the total dataset size should maintain the same as original\n",
    "    dataset_dict.update({0:dataset})\n",
    "    \n",
    "    p = index.Property()\n",
    "    p.leaf_capacity = 100 # cannot be less than 100, indicate the maximum capacity\n",
    "    p.fill_factor = 0.5\n",
    "    p.overwrite = True\n",
    "\n",
    "    idx = index.Index(DatasetGenerator(queryset), properties = p) # Rtree index for queries, ONLY thise queries\n",
    "    \n",
    "    # accumulation histogram for fast query\n",
    "    hist, edges = np.histogramdd(dataset, bins = bins)\n",
    "    accu_hist = CreatePrefixSumHist(hist)\n",
    "    \n",
    "    can_split = True\n",
    "    \n",
    "    #print(kdnode_dict)\n",
    "    if len(kdnode_dict) == 0:\n",
    "        kdnode_dict.update({root_node[-4]:root_node}) # in case it's not in the dict\n",
    "    \n",
    "    accu_count = accu_count_list[0] # newly add attribute, the total kdnodes generated, including the intermediate\n",
    "    \n",
    "    while can_split:\n",
    "        #print('current kdnodes: ', len(kdnodes)), for showing progress\n",
    "        can_split = False\n",
    "        \n",
    "        for i in range(len(kdnodes)):\n",
    "            \n",
    "            if kdnodes[i][1] <= 2 * min_block_size: # including those marked as -1, i.e., deleted\n",
    "                continue\n",
    "                \n",
    "            # try to split\n",
    "            benefits = []\n",
    "            max_skip = 0\n",
    "            max_skip_dim = 0\n",
    "            max_skip_value = 0\n",
    "            temp_dataset = np.copy(dataset_dict[i])\n",
    "            \n",
    "            for j in range(len(candidate_cut_pos)):\n",
    "                \n",
    "                is_split, skip = try_split_approximate(kdnodes[i], candidate_cut_pos[j], dataset, queryset, \n",
    "                                                       idx, min_block_size, accu_hist, domains)\n",
    "                benefits.append(skip)\n",
    "                \n",
    "                if skip > max_skip:\n",
    "                    max_skip = skip\n",
    "                    max_skip_dim = candidate_cut_pos[j][0]\n",
    "                    max_skip_value = candidate_cut_pos[j][1]\n",
    "                    \n",
    "            if max(benefits) <= 0:\n",
    "                can_split = False\n",
    "                break\n",
    "            else:\n",
    "                # perform split, at this place, we keep the exact size\n",
    "                perform_split(i, kdnodes, max_skip_dim, max_skip_value, temp_dataset, dataset_dict, kdnode_dict, accu_count)\n",
    "                can_split = True\n",
    "                accu_count += 2\n",
    "    \n",
    "    \n",
    "    accu_count_list[0] = accu_count\n",
    "    return kdnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[0, 6],\n",
      "       [0, 3]]), 28, 7, 3, -1, -1], [array([[ 6,  7],\n",
      "       [ 0, 10]]), 11, 5, 2, -1, -1], [array([[ 0,  3],\n",
      "       [ 5, 10]]), 20, 9, 4, -1, -1], [array([[ 7, 10],\n",
      "       [ 0,  5]]), 18, 11, 6, -1, -1], [array([[0, 6],\n",
      "       [3, 5]]), 14, 8, 3, -1, -1], [array([[ 3,  6],\n",
      "       [ 5, 10]]), 15, 10, 4, -1, -1], [array([[ 7, 10],\n",
      "       [ 5, 10]]), 15, 12, 6, -1, -1]]\n",
      "= = =\n",
      "{0: [[[0, 10], [0, 10]], 121, 0, -1, 1, 2], 1: [array([[ 0,  6],\n",
      "       [ 0, 10]]), 77, 1, 0, 3, 4], 2: [array([[ 6, 10],\n",
      "       [ 0, 10]]), 44, 2, 0, 5, 6], 3: [array([[0, 6],\n",
      "       [0, 5]]), 42, 3, 1, 7, 8], 4: [array([[ 0,  6],\n",
      "       [ 5, 10]]), 35, 4, 1, 9, 10], 5: [array([[ 6,  7],\n",
      "       [ 0, 10]]), 11, 5, 2, -1, -1], 6: [array([[ 7, 10],\n",
      "       [ 0, 10]]), 33, 6, 2, 11, 12], 7: [array([[0, 6],\n",
      "       [0, 3]]), 28, 7, 3, -1, -1], 8: [array([[0, 6],\n",
      "       [3, 5]]), 14, 8, 3, -1, -1], 9: [array([[ 0,  3],\n",
      "       [ 5, 10]]), 20, 9, 4, -1, -1], 10: [array([[ 3,  6],\n",
      "       [ 5, 10]]), 15, 10, 4, -1, -1], 11: [array([[ 7, 10],\n",
      "       [ 0,  5]]), 18, 11, 6, -1, -1], 12: [array([[ 7, 10],\n",
      "       [ 5, 10]]), 15, 12, 6, -1, -1]}\n",
      "= = =\n",
      "[12]\n",
      "= = =\n",
      "[[[0, 10], [0, 10]], 121, 0, -1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# # = = = Unit Test = = =\n",
    "# tiny_dataset = []\n",
    "# for i in range(11):\n",
    "#     for j in range(11):\n",
    "#         tiny_dataset.append([i,j])\n",
    "# tiny_dataset = np.array(tiny_dataset)\n",
    "\n",
    "# tiny_query_set = [ [[1,3.5],[1,3.5]], [[3,6],[5,8]], [[7,8],[3,6]] ]\n",
    "# tiny_block_size = 10\n",
    "# tiny_domains = [[0,10],[0,10]]\n",
    "\n",
    "# root_node = [[[0,10],[0,10]],121,0,-1,-1,-1]\n",
    "# kdnode_dict = {}\n",
    "# accu_count_list = [0]\n",
    "\n",
    "# tiny_qdtree_kdnodes = LKD_Robust(tiny_dataset, tiny_query_set, tiny_domains, tiny_block_size, \n",
    "#                                  (10,10),accu_count_list, kdnode_dict, root_node)\n",
    "\n",
    "# print(tiny_qdtree_kdnodes)\n",
    "# print(\"= = =\")\n",
    "# print(kdnode_dict)\n",
    "# print(\"= = =\")\n",
    "# print(accu_count_list)\n",
    "# print(\"= = =\")\n",
    "# print(root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # = = = Unit Test = = =\n",
    "# subnode_ids = find_all_leafnode_ids(1, kdict)\n",
    "# print(subnode_ids)\n",
    "\n",
    "# subnode_ids = find_all_subnode_ids(1, kdict)\n",
    "# print(subnode_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTICE: the root node will not be re inserted into the dict! But its children index will be changed\n",
    "def KDPartition(dataset, current_dim, data_threshold, root_node, kdnode_dict, accu_count_list):\n",
    "    \n",
    "    current_size = len(dataset)\n",
    "    if current_size <= data_threshold:\n",
    "        return [root_node] # here we assume the children nodes are -1 and -1\n",
    "        \n",
    "    # try partition this node into 2\n",
    "    median = np.median(dataset[:,current_dim])\n",
    "    \n",
    "    sub_domains1 = np.copy(root_node[0])\n",
    "    sub_domains1[current_dim][1] = median\n",
    "    sub_domains2 = np.copy(root_node[0])\n",
    "    sub_domains2[current_dim][0] = median\n",
    "    \n",
    "    sub_dataset1 = dataset[dataset[:,current_dim] <= median]\n",
    "    sub_dataset2 = dataset[dataset[:,current_dim] > median]\n",
    "    \n",
    "    if len(sub_dataset1) < data_threshold or len(sub_dataset2) < data_threshold:\n",
    "        return [root_node]\n",
    "    \n",
    "    sub_kdnode_1 = [sub_domains1, len(sub_dataset1), accu_count_list[0] + 1, root_node[-4], -1, -1]\n",
    "    sub_kdnode_2 = [sub_domains2, len(sub_dataset2), accu_count_list[0] + 2, root_node[-4], -1, -1]\n",
    "    \n",
    "    root_node[-2] = sub_kdnode_1[-4]\n",
    "    root_node[-1] = sub_kdnode_2[-4]\n",
    "    \n",
    "    kdnode_dict.update({sub_kdnode_1[-4]: sub_kdnode_1})\n",
    "    kdnode_dict.update({sub_kdnode_2[-4]: sub_kdnode_2})\n",
    "    \n",
    "    accu_count_list[0] += 2\n",
    "    \n",
    "    current_dim += 1\n",
    "    if current_dim >= len(root_node[0]):\n",
    "        current_dim %= len(root_node[0])\n",
    "        \n",
    "    kdnodes = []\n",
    "    kdnodes += KDPartition(sub_dataset1, current_dim, data_threshold, sub_kdnode_1, kdnode_dict, accu_count_list)\n",
    "    kdnodes += KDPartition(sub_dataset2, current_dim, data_threshold, sub_kdnode_2, kdnode_dict, accu_count_list)\n",
    "    \n",
    "    return kdnodes\n",
    "\n",
    "def sub_dataset(dataset, domain):\n",
    "    constraints = []\n",
    "    for i in range(len(domain)):\n",
    "        constraint_1 = dataset[:,i] >= domain[i][0]\n",
    "        constraint_2 = dataset[:,i] < domain[i][1]\n",
    "        constraints.append(constraint_1)\n",
    "        constraints.append(constraint_2)\n",
    "    constraint = np.all(constraints, axis=0)\n",
    "    return dataset[constraint]\n",
    "\n",
    "\n",
    "# perform kdtree partition for those nodes that are greater than 2*threshold\n",
    "def post_kdnode_partition(kdnodes, data_threshold, dataset, kdnode_dict, accu_count_list):\n",
    "    \n",
    "    processed_kdnodes = [] # the leaf nodes\n",
    "    \n",
    "    for i in range(len(kdnodes)):\n",
    "        if kdnodes[i][1] > 2 * data_threshold:\n",
    "            temp_dataset = sub_dataset(dataset, kdnodes[i][0])\n",
    "            if kdnodes[i][-4] == 8:\n",
    "                print('process node 8 in post_partition (before): ', kdnodes[i])\n",
    "            processed_kdnodes += KDPartition(temp_dataset, 0, data_threshold, kdnodes[i], kdnode_dict, accu_count_list)\n",
    "            if kdnodes[i][-4] == 8:\n",
    "                print('process node 8 in post_partition (after): ', kdnodes[i])\n",
    "        else:\n",
    "            processed_kdnodes.append(kdnodes[i])\n",
    "    \n",
    "    return processed_kdnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process node 8 in post_partition (before):  [array([[0, 6],\n",
      "       [3, 5]]), 14, 8, 3, -1, -1]\n",
      "process node 8 in post_partition (after):  [array([[0, 6],\n",
      "       [3, 5]]), 14, 8, 3, 19, 20]\n",
      "[[array([[0, 2],\n",
      "       [0, 3]]), 9, 13, 7, -1, -1], [array([[2, 6],\n",
      "       [0, 3]]), 9, 14, 7, -1, -1], [array([[ 6,  7],\n",
      "       [ 0, 10]]), 11, 5, 2, -1, -1], [array([[ 0,  1],\n",
      "       [ 5, 10]]), 10, 15, 9, -1, -1], [array([[ 1,  3],\n",
      "       [ 5, 10]]), 5, 16, 9, -1, -1], [array([[7, 8],\n",
      "       [0, 5]]), 10, 17, 11, -1, -1], [array([[ 8, 10],\n",
      "       [ 0,  5]]), 5, 18, 11, -1, -1], [array([[0, 2],\n",
      "       [3, 5]]), 6, 19, 8, -1, -1], [array([[2, 6],\n",
      "       [3, 5]]), 6, 20, 8, -1, -1], [array([[ 3,  4],\n",
      "       [ 5, 10]]), 10, 21, 10, -1, -1], [array([[ 4,  6],\n",
      "       [ 5, 10]]), 5, 22, 10, -1, -1], [array([[ 7,  8],\n",
      "       [ 5, 10]]), 10, 23, 12, -1, -1], [array([[ 8, 10],\n",
      "       [ 5, 10]]), 5, 24, 12, -1, -1]]\n",
      "= = =\n",
      "{0: [[[0, 10], [0, 10]], 121, 0, -1, 1, 2], 1: [array([[ 0,  6],\n",
      "       [ 0, 10]]), 77, 1, 0, 3, 4], 2: [array([[ 6, 10],\n",
      "       [ 0, 10]]), 44, 2, 0, 5, 6], 3: [array([[0, 6],\n",
      "       [0, 5]]), 42, 3, 1, 7, 8], 4: [array([[ 0,  6],\n",
      "       [ 5, 10]]), 35, 4, 1, 9, 10], 5: [array([[ 6,  7],\n",
      "       [ 0, 10]]), 11, 5, 2, -1, -1], 6: [array([[ 7, 10],\n",
      "       [ 0, 10]]), 33, 6, 2, 11, 12], 7: [array([[0, 6],\n",
      "       [0, 3]]), 28, 7, 3, 13, 14], 8: [array([[0, 6],\n",
      "       [3, 5]]), 14, 8, 3, 19, 20], 9: [array([[ 0,  3],\n",
      "       [ 5, 10]]), 20, 9, 4, 15, 16], 10: [array([[ 3,  6],\n",
      "       [ 5, 10]]), 15, 10, 4, 21, 22], 11: [array([[ 7, 10],\n",
      "       [ 0,  5]]), 18, 11, 6, 17, 18], 12: [array([[ 7, 10],\n",
      "       [ 5, 10]]), 15, 12, 6, 23, 24], 13: [array([[0, 2],\n",
      "       [0, 3]]), 9, 13, 7, -1, -1], 14: [array([[2, 6],\n",
      "       [0, 3]]), 9, 14, 7, -1, -1], 15: [array([[ 0,  1],\n",
      "       [ 5, 10]]), 10, 15, 9, -1, -1], 16: [array([[ 1,  3],\n",
      "       [ 5, 10]]), 5, 16, 9, -1, -1], 17: [array([[7, 8],\n",
      "       [0, 5]]), 10, 17, 11, -1, -1], 18: [array([[ 8, 10],\n",
      "       [ 0,  5]]), 5, 18, 11, -1, -1], 19: [array([[0, 2],\n",
      "       [3, 5]]), 6, 19, 8, -1, -1], 20: [array([[2, 6],\n",
      "       [3, 5]]), 6, 20, 8, -1, -1], 21: [array([[ 3,  4],\n",
      "       [ 5, 10]]), 10, 21, 10, -1, -1], 22: [array([[ 4,  6],\n",
      "       [ 5, 10]]), 5, 22, 10, -1, -1], 23: [array([[ 7,  8],\n",
      "       [ 5, 10]]), 10, 23, 12, -1, -1], 24: [array([[ 8, 10],\n",
      "       [ 5, 10]]), 5, 24, 12, -1, -1]}\n",
      "= = =\n",
      "[24]\n",
      "= = =\n",
      "[[[0, 10], [0, 10]], 121, 0, -1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# # = = = Unit Test = = =\n",
    "# tiny_dataset = []\n",
    "# for i in range(11):\n",
    "#     for j in range(11):\n",
    "#         tiny_dataset.append([i,j])\n",
    "# tiny_dataset = np.array(tiny_dataset)\n",
    "\n",
    "# # defined in the LKD_Robust unit test\n",
    "# # root_node = [[[0,10],[0,10]],121,0,-1,-1,-1]\n",
    "# # kdnode_dict = {}\n",
    "# # accu_count_list = [0]\n",
    "\n",
    "# # processed_kdnodes = KDPartition(tiny_dataset, 0, 5, root_node, kdnode_dict, accu_count_list)\n",
    "\n",
    "# processed_kdnodes = post_kdnode_partition(tiny_qdtree_kdnodes, 5, tiny_dataset, kdnode_dict, accu_count_list)\n",
    "# print(processed_kdnodes)\n",
    "# print(\"= = =\")\n",
    "# print(kdnode_dict)\n",
    "# print(\"= = =\")\n",
    "# print(accu_count_list)\n",
    "# print(\"= = =\")\n",
    "# print(root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LKD_Robust_Initialization(dataset, queryset, domain, data_threshold, query_threshold, \n",
    "                              hist_m, hist_n, random_query_percentage = 0.5):\n",
    "    \n",
    "    filtered_queries, query_hist = filter_distribution_query(queryset, domain, hist_m, hist_n, query_threshold)\n",
    "    \n",
    "    kdnode_dict, accu_count_list = {}, [0]\n",
    "    root_node = [domain, len(dataset), 0, -1, -1, -1]\n",
    "    qdtree_kdnodes = LKD_Robust(dataset, filtered_queries, domain, data_threshold, (hist_m,hist_n), accu_count_list, kdnode_dict, root_node)\n",
    "    processed_kdnodes = post_kdnode_partition(qdtree_kdnodes, data_threshold, dataset, kdnode_dict, accu_count_list)\n",
    "    \n",
    "    p = index.Property()\n",
    "    p.leaf_capacity = 100 # cannot be less than 100, indicate the maximum capacity\n",
    "    p.fill_factor = 0.5\n",
    "    p.overwrite = True\n",
    "\n",
    "    # create index for the kdnodes\n",
    "    kdnode_idx = index.Index(properties = p) # Rtree index\n",
    "    for i in range(len(processed_kdnodes)):\n",
    "        if processed_kdnodes[i][-4] == 164:\n",
    "            print('insert 164 at initialization')\n",
    "        kdnode_idx.insert(processed_kdnodes[i][-4], kdnode_2_border(processed_kdnodes[i]), processed_kdnodes[i])\n",
    "\n",
    "    query_idx = index.Index(properties = p) # Rtree index\n",
    "    for i in range(len(queryset)):\n",
    "        query_idx.insert(i, (queryset[i][0][0],queryset[i][1][0],queryset[i][0][1],queryset[i][1][1]), queryset[i])\n",
    "        \n",
    "    return processed_kdnodes, kdnode_dict, accu_count_list, kdnode_idx, query_idx, query_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# window size should be the same as initial queryset size\n",
    "# the initial \n",
    "def LKD_Robust_Incremental(dataset, window_size, initial_queryset, continous_queryset, kdnode_dict, kdnode_idx, query_idx, query_hist, \n",
    "                           accu_count_list, domain, data_threshold, query_threshold, hist_m, hist_n, random_query_percentage = 0.5):\n",
    "    \n",
    "    initial_query_size = query_idx.get_size()\n",
    "        \n",
    "    total_queryset = initial_queryset + continous_queryset\n",
    "    total_queryset = np.array(total_queryset)\n",
    "    \n",
    "    for i in range(initial_query_size, len(total_queryset)):\n",
    "        print(i)\n",
    "        # add new query\n",
    "        hist_region_index = InserQueryIntoHist(i, total_queryset[i], query_hist, domain, hist_m, hist_n, query_threshold)\n",
    "        \n",
    "        query_idx.insert(i, query_2_border(total_queryset[i]), total_queryset[i])\n",
    "        \n",
    "        if len(hist_region_index) > 0:\n",
    "            #print(hist_region_index)\n",
    "            repartition_for_adaptation(total_queryset, hist_region_index, hist_m, hist_n, dataset, domain, data_threshold, \n",
    "                                       query_threshold, kdnode_idx, query_idx, kdnode_dict, accu_count_list)\n",
    "        \n",
    "        # TODO: this should also include the robustness operation, i.e., post_partition !!!\n",
    "        \n",
    "        if i < window_size:\n",
    "            continue\n",
    "        \n",
    "        # remove old query\n",
    "        hist_region_index = RemoveQueryFromHist(i-window_size, total_queryset[i-window_size], query_hist, \n",
    "                                                domain, hist_m, hist_n, query_threshold)\n",
    "        \n",
    "        query_idx.delete(i-window_size, query_2_border(total_queryset[i-window_size]))\n",
    "        \n",
    "        if len(hist_region_index) > 0:\n",
    "            # repartition for robustness\n",
    "            repartition_for_robustness(hist_region_index, hist_m, hist_n, dataset, domain, data_threshold, query_threshold, \n",
    "                                        kdnode_idx, query_idx, kdnode_dict, accu_count_list)  \n",
    "    \n",
    "    return kdnode_dict, kdnode_idx, query_idx, query_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_query(path):\n",
    "    query_set = np.genfromtxt(path, delimiter=' ')\n",
    "    query_set = query_set.reshape(len(query_set),-1,2)\n",
    "    return query_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# = = = Unit Test = = =\n",
    "original_domains = [\\\n",
    "    [1,1.20000000e+07],\\\n",
    "    [1,4.00000000e+05],\\\n",
    "    [1,2.00000000e+04],\\\n",
    "    [1,7.00000000e+00],\\\n",
    "    [1,5.00000000e+01],\\\n",
    "    [900.99,1.04899500e+05],\\\n",
    "    [0,1.00000000e-01],\\\n",
    "    [0,8.00000000e-02]\\\n",
    "]\n",
    "original_domains = np.asarray(original_domains)\n",
    "# original_dataset = genfromtxt('/Users/lizhe/Desktop/LearnedKDTree/DataAndWorkload/SyntheticData/TPCH_12M_8Field.csv', delimiter=',')\n",
    "original_dataset = np.genfromtxt('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Legacy/data/TPCH_12M_8Field.csv', delimiter=',')\n",
    "used_dimensions = [1,2]\n",
    "dataset = np.copy(original_dataset)\n",
    "dataset = dataset[:,used_dimensions]\n",
    "domains_ = original_domains[used_dimensions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# = = = Unit Test = = =\n",
    "fusion_query = load_query('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Robust/query/fusion.csv') # 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_threshold = 5000\n",
    "query_threshold = 5\n",
    "hist_m, hist_n = 1000, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process node 8 in post_partition (before):  [array([[1.32557467e+05, 1.75056528e+05],\n",
      "       [1.00000000e+00, 1.46852314e+04]]), 934456, 8, 3, -1, -1]\n",
      "process node 8 in post_partition (after):  [array([[1.32557467e+05, 1.75056528e+05],\n",
      "       [1.00000000e+00, 1.46852314e+04]]), 934456, 8, 3, 1417, 1418]\n",
      "insert 164 at initialization\n"
     ]
    }
   ],
   "source": [
    "# = = = Unit Test = = =\n",
    "processed_kdnodes, kdnode_dict, accu_count_list, kdnode_idx, query_idx, query_hist = LKD_Robust_Initialization(\n",
    "    dataset, fusion_query, domains_, data_threshold, query_threshold, hist_m, hist_n, random_query_percentage = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(processed_kdnodes[0:20])\n",
    "for i in range(len(processed_kdnodes)):\n",
    "    if processed_kdnodes[i][-3] == 8:\n",
    "        print(processed_kdnodes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537\n",
      "3073\n",
      "rtree.index.Index(bounds=[1.0, 1.0, 400000.0, 20000.0], size=1537)\n",
      "[3072]\n",
      "rtree.index.Index(bounds=[1.0, 1.0, 400000.0, 20000.0], size=100)\n"
     ]
    }
   ],
   "source": [
    "# = = = Unit Test = = =\n",
    "print(len(processed_kdnodes))\n",
    "print(len(kdnode_dict))\n",
    "print(kdnode_idx)\n",
    "print(accu_count_list)\n",
    "print(query_idx)\n",
    "# print(query_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# = = = Unit Test = = =\n",
    "continous_fusion_query = load_query('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Robust/query/continous_fusion.csv') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not isinstance(fusion_query, list):\n",
    "    fusion_query = fusion_query.tolist()\n",
    "if not isinstance(continous_fusion_query, list):\n",
    "    continous_fusion_query = continous_fusion_query.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n"
     ]
    }
   ],
   "source": [
    "# = = = Unit Test = = =\n",
    "window_size = 100\n",
    "kdnode_dict, kdnode_idx, query_idx, query_hist = LKD_Robust_Incremental(\n",
    "    dataset, window_size, fusion_query, continous_fusion_query, kdnode_dict, kdnode_idx, query_idx, query_hist, \n",
    "    accu_count_list, domains_, data_threshold, query_threshold, hist_m, hist_n, random_query_percentage = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def Query(queries, kdnodes):\n",
    "    \n",
    "    counts_partitions = []\n",
    "    counts_records = []\n",
    "    counts_total = 0\n",
    "    \n",
    "    count_single_query = 0;\n",
    "    count_single_query_records = 0\n",
    "    \n",
    "    # number of dimensions\n",
    "    dims = int(len(queries[0]))\n",
    "    \n",
    "    # for each query\n",
    "    for i in range(len(queries)):\n",
    "        \n",
    "        count_single_query = 0\n",
    "        count_single_query_records = 0\n",
    "        \n",
    "        # check for intersection for each kdnode\n",
    "        for j in range(len(kdnodes)):\n",
    "            \n",
    "            intersection_tag = True\n",
    "            \n",
    "            # for each dimension\n",
    "            for k in range(dims):\n",
    "                \n",
    "                # an intersection holds if it intersecs in all dimensions\n",
    "                if queries[i][k][0] >= kdnodes[j][0][k][1] or queries[i][k][1] <= kdnodes[j][0][k][0]:\n",
    "                    intersection_tag = False\n",
    "                    break\n",
    "                \n",
    "            # if the query intersect with this kdnode\n",
    "            if intersection_tag:\n",
    "                count_single_query += 1\n",
    "                count_single_query_records += kdnodes[j][1] # number of records in this partition\n",
    "            \n",
    "        counts_partitions.append(count_single_query)\n",
    "        counts_records.append(count_single_query_records)\n",
    "        counts_total += count_single_query_records\n",
    "    \n",
    "    #print(\"blocks IO: \", counts)\n",
    "    print(\"average partitions each query overlap(average): \", statistics.mean(counts_partitions))\n",
    "    print(\"average records each query retrieve(average): \", statistics.mean(counts_records))\n",
    "    print(\"total records that all the queries retrieve: \", counts_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average partitions each query overlap(average):  6.46\n",
      "average records each query retrieve(average):  48976.34\n",
      "total records that all the queries retrieve:  2448817\n"
     ]
    }
   ],
   "source": [
    "testing_set = load_query('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Robust/query/testing.csv')\n",
    "Query(testing_set, processed_kdnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === KDTree Visualization ===\n",
    "#\n",
    "# restricted to 2D\n",
    "#\n",
    "# @kdnodes: the generated kdnodes, domains in them are ordered according to the learned split dimension order,\n",
    "#   should only generated on the domains for visualization?\n",
    "# @query: the query in the query dimension order, should be the same as the order of 'kdnode domains'\n",
    "# @domains: the domains for visualization, should be in the origin order\n",
    "# @realtive_order: whether to adjust the order of domains in kdnodes to corresponding the 'domains' parameteer\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "def visualize_kdnodes_and_query(kdnodes, query, domains):\n",
    "    \n",
    "    fig, ax = plt.subplots(1)\n",
    "    \n",
    "    plt.xlim(domains[0][0],domains[0][1])\n",
    "    plt.ylim(domains[1][0],domains[1][1])\n",
    "    # transform the queries into boxes\n",
    "    \n",
    "    # first plot all the kdnodes\n",
    "    for i in range(len(kdnodes)):\n",
    "        \n",
    "        kd_domains = kdnodes[i][0]\n",
    "        kd_domains = np.asarray(kd_domains)\n",
    "        \n",
    "        lower1 = kd_domains[0][0]\n",
    "        upper1 = kd_domains[0][1]\n",
    "        lower2 = kd_domains[1][0]\n",
    "        upper2 = kd_domains[1][1]\n",
    "        \n",
    "        rect = Rectangle((lower1,lower2),upper1-lower1,upper2-lower2,fill=False,edgecolor='b',linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    # plot the queries\n",
    "    for i in range(len(query)):\n",
    "        \n",
    "        lower1 = query[i][0][0]\n",
    "        upper1 = query[i][0][1]\n",
    "        lower2 = query[i][1][0]\n",
    "        upper2 = query[i][1][1]\n",
    "        \n",
    "        rect = Rectangle((lower1,lower2),upper1-lower1,upper2-lower2,fill=False,edgecolor='r',linewidth=3)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LKD_Robust_kdnodes = []\n",
    "for key,value in kdnode_dict.items():\n",
    "    if value[-1] == -1 and value[-2] == -1:\n",
    "        LKD_Robust_kdnodes.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAD8CAYAAAC7IukgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_kdnodes_and_query(LKD_Robust_kdnodes, continous_fusion_query[-100:], domains_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average partitions each query overlap(average):  7.76\n",
      "average records each query retrieve(average):  55316.46\n",
      "total records that all the queries retrieve:  5531646\n"
     ]
    }
   ],
   "source": [
    "# Test Query Cost\n",
    "Query(continous_fusion_query[-100:], LKD_Robust_kdnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# consider the baseline of using the last 100 queries\n",
    "qd_root_node = [domains_, len(dataset), 0, -1, -1, -1]\n",
    "qd_kdnode_dict = {}\n",
    "pure_Qd_Tree_kdnodes = LKD_Robust(dataset, queryset, domains, min_block_size, (1000,1000), accu_count_list, qd_kdnode_dict, qd_root_node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
