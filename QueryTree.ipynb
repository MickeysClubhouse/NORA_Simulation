{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QueryTreeNode:\n",
    "    \n",
    "    def __init__(self, id, lower = 0, upper = 0, level = 0):\n",
    "        self.id = id # should be identical at least in current QueryTree's current dimension\n",
    "        self.lower = lower # lower border\n",
    "        self.upper = upper # upper border\n",
    "        \n",
    "#         self.border = [] # all the dimensions\n",
    "#         self.is_primary = False\n",
    "#         self.primary_index = -1\n",
    "#         self.status = 0 # 0: valid, 1: invalid\n",
    "#         self.level = level # tree level, start from root - 0\n",
    "        \n",
    "        self.pid = [] # parent id, may be multiple\n",
    "        self.cid = [] # child id, may be multiple\n",
    "        self.previd = -1 # the previous node at the same level, by default -1, i.e., none\n",
    "        self.nextid = -1 # the next node at the same level, by default -1, i.e., none\n",
    "\n",
    "# queryset should have been pruned to\n",
    "\n",
    "class QueryTree:\n",
    "    \n",
    "    def __init__(self, dimension=0):\n",
    "        self.queryset = []\n",
    "        self.dimension = dimension\n",
    "        self.size = -1\n",
    "        \n",
    "        self.root = QueryTreeNode(-1)\n",
    "        self.node_dict = {} # a dictionary mapping node id to node object\n",
    "        self.primary_nodes = [] # a array store the primary nodes (i.e., the node just below the root)\n",
    "        self.node_count = 0\n",
    "    \n",
    "    def loadQuerySetFromQueries(self, query):\n",
    "        '''\n",
    "        queries: [i,k,0/1] numpy object  i: ith query, k: kth dimension, 0/1: lower/upper\n",
    "        '''\n",
    "        self.queryset = query[:,self.dimension,:]    # [i, 2], each row has L U value\n",
    "        if len(self.queryset) == 0:\n",
    "            self.size = 0\n",
    "            return\n",
    "        self.queryset = np.unique(self.queryset,axis=0) # remove duplicated queries\n",
    "        self.queryset = self.queryset[np.lexsort((-self.queryset[:,1],self.queryset[:,0]))] # sort by L first, then by U (reverse)\n",
    "        \n",
    "        # add an extra column for id at the end\n",
    "        ids = np.array([[i] for i in range(len(self.queryset))]) # [i]: as the concat should has the same dimensions\n",
    "        self.queryset = np.concatenate((self.queryset, ids), axis=1)\n",
    "    \n",
    "    def loadQuerySetFromFile(self, filename):\n",
    "        \n",
    "        '''\n",
    "        Load the query form file separator by white space containing L U in each query dimension (interleaved),\n",
    "          extract the target dimension, sort according to L first then -U. Append id at the last column.\n",
    "        \n",
    "        The queryset format in file:  L1 U1 L2 U2 L3 U3 ... (seperate by ' ')\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.queryset = np.genfromtxt(filename, delimiter=' ')\n",
    "        self.queryset = self.queryset.reshape(len(self.queryset),-1,2)\n",
    "        self.queryset = self.queryset[:,self.dimension,:]    # [i, 2], each row has L U value\n",
    "        self.queryset = np.unique(self.queryset,axis=0) # remove duplicated queries\n",
    "        self.queryset = self.queryset[np.lexsort((-self.queryset[:,1],self.queryset[:,0]))] # sort by L first, then by U (reverse)\n",
    "        \n",
    "        # add an extra column for id at the end\n",
    "        ids = np.array([[i] for i in range(len(self.queryset))]) # [i]: as the concat should has the same dimensions\n",
    "        self.queryset = np.concatenate((self.queryset, ids), axis=1)\n",
    "        \n",
    "    def buildQueryTree(self):\n",
    "        \n",
    "        '''\n",
    "        Should call loadQuerySetFromFile() first before calling this function.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        prev_node_id = 0\n",
    "        \n",
    "        for i in range(len(self.queryset)):\n",
    "            \n",
    "            current_query_lower = self.queryset[i,0]\n",
    "            current_query_upper = self.queryset[i,1]\n",
    "            \n",
    "            # create a QueryNode for this query\n",
    "            qNode = QueryTreeNode(i, current_query_lower, current_query_upper)\n",
    "            \n",
    "            # looking for queries that contains it, those queries are already sorted by L then -U. Notice this is a copy (no reference)\n",
    "            container_queryset = self.queryset[ (self.queryset[:,0]<= current_query_lower) & (self.queryset[:,1]>=current_query_upper) ]\n",
    "            \n",
    "            if len(container_queryset) <= 1: # itself\n",
    "                # add this node under root directly\n",
    "                self.root.cid.append(i)\n",
    "                qNode.pid.append(self.root.id) # append root id into its parent\n",
    "                \n",
    "                self.primary_nodes.append(qNode)\n",
    "                self.node_dict.update({i:qNode})  # add this QueryNode to the dictionary, do it here as the following lines required\n",
    "                \n",
    "                if i == 0:\n",
    "                    qNode.previd = -1\n",
    "                    continue\n",
    "                \n",
    "                # handling prev node and next node\n",
    "                qNode.previd = prev_node_id\n",
    "                self.node_dict[prev_node_id].nextid = i\n",
    "                prev_node_id = i\n",
    "                \n",
    "            else:\n",
    "                # add this nodes under the previous queries, from reverse order!\n",
    "                for j in reversed(range(len(container_queryset))):\n",
    "                    container_id = int(container_queryset[j,-1]) # the last column is the id\n",
    "                    if container_id == i: # itself\n",
    "                        continue    \n",
    "                    if container_id == -1: # ruled out\n",
    "                        continue\n",
    "                    \n",
    "                    self.node_dict[container_id].cid.append(i)\n",
    "                    qNode.pid.append(container_id)\n",
    "                    \n",
    "                    # remove the nodes contain this container_id from container_queryset !!!\n",
    "                    container_lower = container_queryset[j,0]\n",
    "                    container_upper = container_queryset[j,1]\n",
    "                    # mark the id as -1, denoting these nodes are invalid\n",
    "                    container_queryset[(container_queryset[:,0]<= container_lower)&(container_queryset[:,1]>=container_upper),-1] = -1  \n",
    "                \n",
    "                # add this QueryNode to the dictionary\n",
    "                self.node_dict.update({i:qNode})\n",
    "    \n",
    "    def queryValue(self, mid_value):\n",
    "        '''\n",
    "        Query if an position (in domain, should be the median position) contains some queries.\n",
    "        If no, it's good.\n",
    "        If yes, find our the left and right border of that query(queries). \n",
    "        '''\n",
    "        # using binary search to find the node that overlap the position\n",
    "        lower_index = 0\n",
    "        upper_index = len(self.primary_nodes) - 1\n",
    "        mid_index = int((lower_index + upper_index) / 2) # the index of the array\n",
    "        \n",
    "        overlap_flag = False # false for no_overlap\n",
    "        last_visit_node_id = -1\n",
    "        last_visit_node_index = -1\n",
    "        \n",
    "        while True:\n",
    "            current_lower = self.primary_nodes[mid_index].lower\n",
    "            current_upper = self.primary_nodes[mid_index].upper\n",
    "            last_visit_node_id = self.primary_nodes[mid_index].id\n",
    "            last_visit_node_index = mid_index\n",
    "            \n",
    "            if mid_value >= current_lower and mid_value <= current_upper:\n",
    "                overlap_flag = True\n",
    "                break\n",
    "                \n",
    "            elif mid_value > current_upper:\n",
    "                lower_index = mid_index + 1\n",
    "                \n",
    "            elif mid_value < current_lower:\n",
    "                upper_index = mid_index - 1\n",
    "            \n",
    "            if upper_index < lower_index:\n",
    "                break # the overlap flag should be False here\n",
    "            \n",
    "            mid_index = int((lower_index + upper_index) / 2)\n",
    "    \n",
    "        if overlap_flag:\n",
    "            lower_node_id, lower_node_index, upper_node_id, upper_node_index = -1, -1, -1, -1\n",
    "            lower_value = self.primary_nodes[last_visit_node_index].lower\n",
    "            upper_value = self.primary_nodes[last_visit_node_index].upper\n",
    "            # find the borders of the overlap node (all the way till non-overlap)\n",
    "            for i in range(last_visit_node_index, len(self.primary_nodes)-1):\n",
    "                if self.primary_nodes[i+1].lower < self.primary_nodes[i].upper:\n",
    "                    upper_node_id = self.primary_nodes[i+1].id\n",
    "                    upper_node_index = i + 1\n",
    "                    upper_value = self.primary_nodes[i+1].upper\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            for i in range(last_visit_node_index, 0, -1):\n",
    "                if self.primary_nodes[i-1].upper > self.primary_nodes[i].lower:\n",
    "                    lower_node_id = self.primary_nodes[i-1].id\n",
    "                    lower_node_index = i - 1\n",
    "                    lower_value = self.primary_nodes[i-1].lower\n",
    "                else:\n",
    "                    break  \n",
    "                \n",
    "            return True, (last_visit_node_index, lower_value, upper_value, lower_node_id, lower_node_index, upper_node_id, upper_node_index)\n",
    "        else:\n",
    "            return False, ()\n",
    "    \n",
    "    def diveIn(self, node_index, dive_position):\n",
    "        '''\n",
    "        This function dive in the query tree under the dive position. Then any primary node cover this dive position should \n",
    "        be cancelled.\n",
    "        \n",
    "        Currently, it's assumed to be called after queryValue(), such that the first overlap node is known\n",
    "        \n",
    "        node_index: the dive position's corresponding primary query node's index in self.primary_nodes \n",
    "            i.e., first output from cache, the last_visit_node_index\n",
    "        dive_position: a value in this domain\n",
    "        \n",
    "        '''\n",
    "        # find the overlaped primary nodes\n",
    "        overlapped_upper_node_index = node_index\n",
    "        overlapped_lower_node_index = node_index\n",
    "        \n",
    "        for i in range(node_index, len(self.primary_nodes)):\n",
    "            if self.primary_nodes[i].lower <= dive_position:\n",
    "                overlapped_upper_node_index = i\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        for i in reversed(range(node_index)):\n",
    "            if self.primary_nodes[i].upper >= dive_position:\n",
    "                overlapped_lower_node_index = i\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # reorganize the query tree\n",
    "        processed_count = 0\n",
    "        current_index = overlapped_lower_node_index\n",
    "        \n",
    "        prev_node_id = self.primary_nodes[overlapped_lower_node_index].previd\n",
    "        next_node_id = self.primary_nodes[overlapped_upper_node_index].nextid\n",
    "        \n",
    "        new_prim_count = 0\n",
    "        new_prim_nodes_all = []\n",
    "        \n",
    "        while processed_count < overlapped_upper_node_index - overlapped_lower_node_index + 1 :\n",
    "            \n",
    "            processed_node_id = self.primary_nodes[current_index].id\n",
    "            child_nodes_id = self.primary_nodes[current_index].cid\n",
    "                \n",
    "            self.root.cid.remove(processed_node_id)\n",
    "            del self.primary_nodes[current_index]\n",
    "            del self.node_dict[processed_node_id]\n",
    "            \n",
    "            # check the child nodes\n",
    "            for i in range(len(child_nodes_id)):\n",
    "                nid = child_nodes_id[i]\n",
    "                ref = self.node_dict[nid]\n",
    "                ref.pid.remove(processed_node_id)\n",
    "                \n",
    "                # should be added to primary node\n",
    "                if len(ref.pid) == 0:\n",
    "                    # add it to primary node !\n",
    "                    ref.previd = prev_node_id\n",
    "                    if prev_node_id != -1:\n",
    "                        self.node_dict[prev_node_id].nextid = nid\n",
    "                    prev_node_id = nid\n",
    "                    \n",
    "                    ref.pid.append(self.root.id)\n",
    "                    self.root.cid.insert(overlapped_upper_node_index + new_prim_count + 1, nid)\n",
    "                    new_prim_count += 1\n",
    "                    \n",
    "                    # add this node to the primary node cache\n",
    "                    new_prim_nodes_all.append(ref)\n",
    "            \n",
    "            processed_count += 1\n",
    "        \n",
    "        # for the last (to be added) primary node\n",
    "        if len(new_prim_nodes_all) == 0 and prev_node_id != -1:\n",
    "            self.node_dict[prev_node_id].nextid = next_node_id\n",
    "        if len(new_prim_nodes_all) >= 1:\n",
    "            new_prim_nodes_all[len(new_prim_nodes_all)-1].nextid = next_node_id\n",
    "        if next_node_id != -1:\n",
    "            self.node_dict[next_node_id].previd = prev_node_id\n",
    "        \n",
    "        # add these nodes to the primary node\n",
    "        for i in range(len(new_prim_nodes_all)):\n",
    "            self.primary_nodes.insert(overlapped_lower_node_index + i, new_prim_nodes_all[i])\n",
    "        \n",
    "        return overlapped_upper_node_index - overlapped_lower_node_index + 1 # removed queries        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateQueryTree(queryset_filepath, dims):\n",
    "    query_trees = []\n",
    "    for i in range(dims):\n",
    "        qtree = QueryTree(i)\n",
    "        qtree.loadQuerySetFromFile(queryset_filepath)\n",
    "        qtree.buildQueryTree()\n",
    "        query_trees.append(qtree)\n",
    "    return query_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 4.25563989e+03]\n",
      " [1.02341336e+02 4.85909190e+03]\n",
      " [1.52009967e+02 4.36377676e+03]\n",
      " [1.70180435e+02 4.63882393e+03]]\n"
     ]
    }
   ],
   "source": [
    "# # Unit Test\n",
    "# qTree = QueryTree()\n",
    "# qTree.loadQuerySetInNumpy('C:/Users/Cloud/iCloudDrive/HUAWEI_LKD/Dataset/Legacy/query/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = loadQuerySetInNumpy() = = =\n",
      "[[0.   3.   0.  ]\n",
      " [0.5  2.5  1.  ]\n",
      " [1.   4.   2.  ]\n",
      " [1.25 2.25 3.  ]\n",
      " [2.   3.75 4.  ]\n",
      " [3.25 5.25 5.  ]]\n",
      "= = = buildQueryTree() = = =\n",
      "{'id': 0, 'lower': 0.0, 'upper': 3.0, 'level': 0, 'pid': [-1], 'cid': [1], 'previd': -1, 'nextid': 2}\n",
      "{'id': 1, 'lower': 0.5, 'upper': 2.5, 'level': 0, 'pid': [0], 'cid': [3], 'previd': -1, 'nextid': -1}\n",
      "{'id': 2, 'lower': 1.0, 'upper': 4.0, 'level': 0, 'pid': [-1], 'cid': [3, 4], 'previd': 0, 'nextid': 5}\n",
      "{'id': 3, 'lower': 1.25, 'upper': 2.25, 'level': 0, 'pid': [2, 1], 'cid': [], 'previd': -1, 'nextid': -1}\n",
      "{'id': 4, 'lower': 2.0, 'upper': 3.75, 'level': 0, 'pid': [2], 'cid': [], 'previd': -1, 'nextid': -1}\n",
      "{'id': 5, 'lower': 3.25, 'upper': 5.25, 'level': 0, 'pid': [-1], 'cid': [], 'previd': 2, 'nextid': -1}\n",
      "= = = primary_nodes = = =\n",
      "{'id': 0, 'lower': 0.0, 'upper': 3.0, 'level': 0, 'pid': [-1], 'cid': [1], 'previd': -1, 'nextid': 2}\n",
      "{'id': 2, 'lower': 1.0, 'upper': 4.0, 'level': 0, 'pid': [-1], 'cid': [3, 4], 'previd': 0, 'nextid': 5}\n",
      "{'id': 5, 'lower': 3.25, 'upper': 5.25, 'level': 0, 'pid': [-1], 'cid': [], 'previd': 2, 'nextid': -1}\n",
      "= = = queryValue() = = =\n",
      "True (1, 0.0, 5.25, 0, 0, 5, 2)\n",
      "= = = diveIn() = = =\n",
      "{'id': 1, 'lower': 0.5, 'upper': 2.5, 'level': 0, 'pid': [-1], 'cid': [3], 'previd': -1, 'nextid': 4}\n",
      "{'id': 4, 'lower': 2.0, 'upper': 3.75, 'level': 0, 'pid': [-1], 'cid': [], 'previd': 1, 'nextid': 5}\n",
      "{'id': 5, 'lower': 3.25, 'upper': 5.25, 'level': 0, 'pid': [-1], 'cid': [], 'previd': 4, 'nextid': -1}\n",
      "= = = node_dict = = =\n",
      "{'id': 1, 'lower': 0.5, 'upper': 2.5, 'level': 0, 'pid': [-1], 'cid': [3], 'previd': -1, 'nextid': 4}\n",
      "{'id': 3, 'lower': 1.25, 'upper': 2.25, 'level': 0, 'pid': [1], 'cid': [], 'previd': -1, 'nextid': -1}\n",
      "{'id': 4, 'lower': 2.0, 'upper': 3.75, 'level': 0, 'pid': [-1], 'cid': [], 'previd': 1, 'nextid': 5}\n",
      "{'id': 5, 'lower': 3.25, 'upper': 5.25, 'level': 0, 'pid': [-1], 'cid': [], 'previd': 4, 'nextid': -1}\n"
     ]
    }
   ],
   "source": [
    "# # === unit test ===\n",
    "# print(\"= = = loadQuerySetInNumpy() = = =\")\n",
    "# qTree = QueryTree()\n",
    "# qTree.loadQuerySetInNumpy('./TestQuery.csv')\n",
    "# print(qTree.queryset)\n",
    "\n",
    "# print(\"= = = buildQueryTree() = = =\")\n",
    "# qTree.buildQueryTree()\n",
    "# for key in qTree.node_dict:\n",
    "#     print(qTree.node_dict[key].__dict__)\n",
    "\n",
    "# print(\"= = = primary_nodes = = =\")\n",
    "# for node in qTree.primary_nodes:\n",
    "#     print(node.__dict__)\n",
    "\n",
    "# print(\"= = = queryValue() = = =\")\n",
    "# is_overlap, cache = qTree.queryValue(3.0)\n",
    "# print(is_overlap, cache)\n",
    "\n",
    "# print(\"= = = diveIn() = = =\")\n",
    "# qTree.diveIn(cache[0], 3.0)\n",
    "# for node in qTree.primary_nodes:\n",
    "#     print(node.__dict__)\n",
    "# print(\"= = = node_dict = = =\")\n",
    "# for key in qTree.node_dict:\n",
    "#     print(qTree.node_dict[key].__dict__)\n",
    "    \n",
    "# # after dive in, test query again\n",
    "# # print(\"= = = queryValue() = = =\")\n",
    "# # is_overlap, cache = qTree.queryValue(3.0)\n",
    "# # print(is_overlap, cache)\n",
    "\n",
    "# # print(\"= = = diveIn() = = =\")\n",
    "# # qTree.diveIn(cache[0], 3.0)\n",
    "# # for node in qTree.primary_nodes:\n",
    "# #     print(node.__dict__)\n",
    "# # print(\"= = = node_dict = = =\")\n",
    "# # for key in qTree.node_dict:\n",
    "# #     print(qTree.node_dict[key].__dict__)\n",
    "    \n",
    "# # # after dive in, test query again\n",
    "# # print(\"= = = queryValue() = = =\")\n",
    "# # is_overlap, cache = qTree.queryValue(3.0)\n",
    "# # print(is_overlap, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "<class '__main__.QueryTreeNode'>\n",
      "2000\n",
      "2000\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "node = QueryTreeNode\n",
    "test_array = []\n",
    "test_array.append(node)\n",
    "test_dict = {1:node}\n",
    "# node.previd = 10\n",
    "test_dict[1].previd=20\n",
    "print(test_array[0].previd)\n",
    "# del test_array[0]\n",
    "print(test_dict[1])\n",
    "\n",
    "copy_node = deepcopy(node)\n",
    "# copy_node = copy.copy(node)\n",
    "copy_node.previd = 2000\n",
    "print(test_array[0].previd)\n",
    "print(node.previd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 4.25563989e+03]\n",
      " [1.02341336e+02 4.85909190e+03]\n",
      " [1.52009967e+02 4.36377676e+03]\n",
      " [1.70180435e+02 4.63882393e+03]]\n"
     ]
    }
   ],
   "source": [
    "selected = qTree.queryset[(qTree.queryset[:,0]<200) & (qTree.queryset[:,1]<5000)]\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 4.25563989e+03 0.00000000e+00]\n",
      " [1.02341336e+02 4.85909190e+03 1.00000000e+00]\n",
      " [1.52009967e+02 4.36377676e+03 2.00000000e+00]\n",
      " [1.70180435e+02 4.63882393e+03 3.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "ids = np.array([[i] for i in range(len(selected))])\n",
    "selected = np.concatenate((selected, ids), axis=1)\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str\n"
     ]
    }
   ],
   "source": [
    "# a = 'str'\n",
    "# b = a\n",
    "# b += 'lalala'\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# a = [1,2,3]\n",
    "# b = a.copy()\n",
    "# b.append(4)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  30 200]\n",
      " [  1  30 200]\n",
      " [  2  10 200]]\n"
     ]
    }
   ],
   "source": [
    "# a = np.array([[2,30,200], [1,30,200], [2,10,200]])\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  10 200]\n",
      " [  2  30 200]\n",
      " [  1  30 200]]\n"
     ]
    }
   ],
   "source": [
    "# print(a[np.lexsort((-a[:,0],a[:,1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# for j in range(10,0,-1):\n",
    "#     print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# for j in reversed(range(10)):\n",
    "#     print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "# dicts = {1:21, 2:22, 3:33}\n",
    "# dicts[1]+=100\n",
    "# print(dicts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# test_array = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "# print(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2 100]\n",
      " [  4   5 100]\n",
      " [  7   8   9]]\n"
     ]
    }
   ],
   "source": [
    "# test_array[test_array[:,2] <= 6, -1] = 100\n",
    "# print(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2 100]\n",
      " [  4   5   6]]\n"
     ]
    }
   ],
   "source": [
    "# selected[0,-1] = 100\n",
    "# print(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# print(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[1, 2, 3, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# a = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# del a[3]\n",
    "# print(a[3])\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
