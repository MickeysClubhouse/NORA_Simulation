{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Header ===\n",
    "#\n",
    "# @date: 03 / 07 / 2019 (Xi'an)\n",
    "# @author: ZHE LI\n",
    "# @title: Learned KD-Tree\n",
    "#\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Generate Query ===\n",
    "#\n",
    "# by default, use Gaussian distribution to generate the synthetic query workload\n",
    "#\n",
    "# @center_amount: assume the queries are clustered into that amount of clusters; integer\n",
    "# @point_amount: the number of queries in each cluster; interger\n",
    "# @dimensions: the domain of each dimension, the range should at least 8 times the sigma value; array object\n",
    "# @sigma: the sigma of Gaussian distribution of each dimension; array object\n",
    "#\n",
    "# return @temp_queries: array object\n",
    "#\n",
    "import random\n",
    "def generate_query(center_amount=10, point_amount=10, dimensions=[[-180,180],[-90,90]], sigma=[10,5]):\n",
    "    \n",
    "    random.seed()\n",
    "    num_dims = len(dimensions)\n",
    "    \n",
    "    queries = []\n",
    "    for j in range(2*num_dims):\n",
    "        queries.append([])\n",
    "    \n",
    "    # for each cluster\n",
    "    for i in range(center_amount):\n",
    "        \n",
    "        # determin the cluster center on each dimension\n",
    "        cluster_center = []\n",
    "        \n",
    "        # for each dimension\n",
    "        for j in range(num_dims):\n",
    "            \n",
    "            # to assure the distribution do not exceed the border\n",
    "            dim_range = dimensions[j][1]-dimensions[j][0]\n",
    "            center1D = random.randrange(dim_range)\n",
    "            #center1D += (dimensions[j][0] + 4*sigma[j])\n",
    "            cluster_center.append(center1D)\n",
    "            \n",
    "            # for each query\n",
    "            for k in range(point_amount):\n",
    "                \n",
    "                #determin the lower bound\n",
    "                lower1D = random.gauss(center1D, sigma[j])\n",
    "                upper1D = random.gauss(center1D, sigma[j])\n",
    "                \n",
    "                if lower1D <= dimensions[j][0]:\n",
    "                    lower1D = dimensions[j][0]\n",
    "                if lower1D >= dimensions[j][1]:\n",
    "                    lower1D = dimensions[j][1]\n",
    "                if upper1D <= dimensions[j][0]:\n",
    "                    upper1D = dimensions[j][0]\n",
    "                if upper1D >= dimensions[j][1]:\n",
    "                    upper1D = dimensions[j][1]\n",
    "                \n",
    "                if lower1D > upper1D:\n",
    "                    lower1D, upper1D = upper1D, lower1D\n",
    "                    \n",
    "                queries[2*j].append(lower1D)\n",
    "                queries[2*j+1].append(upper1D)\n",
    "                \n",
    "    # transform the query structure\n",
    "    temp_queries = []\n",
    "    values = []\n",
    "    for i in range(len(queries[0])):\n",
    "        for j in range(2*num_dims):\n",
    "            values.append(queries[j][i])\n",
    "        temp_queries.append(values)\n",
    "        values=[]\n",
    "            \n",
    "    # return queries\n",
    "    return temp_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of usage (Generate Query)\n",
    "#\n",
    "dimensions_ = [[1,1.20000000e+07],[1,4.00000000e+05],[1,2.00000000e+04]]\n",
    "sigma_ = [10000,1000,10000]\n",
    "query_collection = generate_query(center_amount=1000, point_amount=10, dimensions=dimensions_, sigma=sigma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Query Bounding ===\n",
    "#\n",
    "# this works for one dimension only !!! An implementation of query bounding.\n",
    "#\n",
    "# @query_collection: the queries in one single dimension; numpy object\n",
    "#\n",
    "# return @bounded_intervals: array object\n",
    "#\n",
    "def getoverlap(al, au, bl, bu):\n",
    "    return max(0, min(au,bu)-max(al,bl))\n",
    "\n",
    "def bounding_union(query_collection):\n",
    "    \n",
    "    # should keep it ordered first by the lower interval !!!!!!\n",
    "    query_collection = query_collection[query_collection[:,0].argsort()]\n",
    "    \n",
    "    remaining_query = query_collection\n",
    "    bounded_intervals = []\n",
    "    \n",
    "    while len(remaining_query) != 0:\n",
    "        \n",
    "        initial_interval = [remaining_query[0][0], remaining_query[0][1]]\n",
    "        temp_interval = []\n",
    "        \n",
    "        for i in range(len(remaining_query)-1):\n",
    "            \n",
    "            overlap = getoverlap(initial_interval[0],initial_interval[1],remaining_query[i+1][0], remaining_query[i+1][1])\n",
    "            \n",
    "            # there is no overlap\n",
    "            if overlap == 0:\n",
    "                temp_interval.append([remaining_query[i+1][0], remaining_query[i+1][1]])\n",
    "            else: # update interval border\n",
    "                initial_interval[0] = min(initial_interval[0], remaining_query[i+1][0])\n",
    "                initial_interval[1] = max(initial_interval[1], remaining_query[i+1][1])\n",
    "                \n",
    "        bounded_intervals.append(initial_interval)\n",
    "        remaining_query = temp_interval\n",
    "    \n",
    "    return bounded_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of usage (Query Bounding)\n",
    "#\n",
    "def bound_queries(query_collection):\n",
    "    # number of dimensions\n",
    "    dims = int(len(query_collection[0])/2)\n",
    "    bounded_queries = []\n",
    "    for i in range(dims):\n",
    "        queries_1dim = query_collection[:,2*i:2*i+2]\n",
    "        bounded_intervals = bounding_union(queries_1dim)\n",
    "        bounded_queries.append(bounded_intervals)\n",
    "        #np.savetxt('/Users/lizhe/Desktop/LearnedKDTree/DataAndWorkload/SyntheticWorkload/Dim'+str(i)+'_QueryBound_TPCH_C1000_P10_S100.csv',bounded_intervals,delimiter=',')\n",
    "    return bounded_queries\n",
    "\n",
    "\n",
    "def query_seperation(query_collection, training_set_percentage = 0.9):\n",
    "    np.random.shuffle(query_collection)\n",
    "    training_set_size = int(training_set_percentage * len(query_collection))\n",
    "    query_collection = np.asarray(query_collection) # as the shuffle make np to array, we need to make it back\n",
    "\n",
    "    training_set = query_collection[0:training_set_size,:]\n",
    "    testing_set = query_collection[training_set_size:-1,:]\n",
    "\n",
    "    return training_set, testing_set\n",
    "\n",
    "training_set, testing_set = query_seperation(query_collection)\n",
    "bounded_queries = bound_queries(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('/Users/lizhe/Desktop/LearnedKDTree/DataAndWorkload/SyntheticWorkload/SyntheticWorkload_TestSet_TPCH_C1000_P10_S50000_500_50.csv',test_set,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Learned KD-Tree Split ===\n",
    "#\n",
    "# asssumption: the query boundings will not overlap. divide the KD-Tree recursively\n",
    "#\n",
    "# @dataset: contains the data only in this subnode; numpy object, place it in the order of Dimorder\n",
    "# @query_bound: contains all the bounds(i.e., bounded_queries), place it in the order of Dimorder; numpy object\n",
    "# @currentDim: the dimension this iteration should focus on, an index in the Dimorder; integer\n",
    "# @Dimorder: the order to split the dimensions; array object\n",
    "# @domains: the current domain of the node of every dimension [first lower, second upper],[]...; array object\n",
    "# @threshold: maximum page size\n",
    "# @level: the current tree depth\n",
    "#\n",
    "# return @kdnodes: contains the domain of each node and the correpsonding records amount, notice the domain is\n",
    "# ordered by Dimorder, the same as order of domains.\n",
    "#\n",
    "def ResuriveDivide(dataset, query_bound, currentDim, Dimorder, domains, threshold, level):\n",
    "    \n",
    "    #print(\"level: \",level)\n",
    "    #print(\"dataset size: \",len(dataset))\n",
    "    \n",
    "    # check if the threshold is already satisfied\n",
    "    total_size = len(dataset)\n",
    "    if total_size <= threshold:\n",
    "        # the kdnodes should be an global object outside the function\n",
    "        kdnodes = []\n",
    "        kdnodes.append([domains,total_size])\n",
    "        return kdnodes\n",
    "    \n",
    "    # the current dimension\n",
    "    # divideDim = Dimorder[currentDim]\n",
    "    divideDim = currentDim # the dataset is already ordered as the Dimorder\n",
    "    \n",
    "    # sort according to the current dimension\n",
    "    dataset = dataset[dataset[:,divideDim].argsort()]\n",
    "    \n",
    "    # find the medium\n",
    "    medium = dataset[int(total_size/2),divideDim]\n",
    "    medium_low = domains[divideDim][0]\n",
    "    medium_up = domains[divideDim][1]\n",
    "    \n",
    "    # start check split position from the medium\n",
    "    split_position = int(total_size/2)\n",
    "    split_low = 0\n",
    "    split_up = total_size\n",
    "    \n",
    "    # check if the split position intersect some query boundings in this dim\n",
    "    for i in range(len(query_bound[divideDim])):\n",
    "        \n",
    "        # if intersect some query bounds\n",
    "        if medium > query_bound[divideDim][i][0] and medium < query_bound[divideDim][i][1]:\n",
    "            \n",
    "            # check if the two end already exceeds domain\n",
    "            if query_bound[divideDim][i][0] < domains[divideDim][0] and query_bound[divideDim][i][1] > domains[divideDim][1]:\n",
    "                break;\n",
    "            \n",
    "            else:\n",
    "                if query_bound[divideDim][i][0] > domains[divideDim][0]:\n",
    "                # get the number of records from medium to the end\n",
    "                    for j in range(split_position-1,-1,-1):\n",
    "                        if dataset[j][divideDim] <= query_bound[divideDim][i][0]:\n",
    "                            split_low = j\n",
    "                            medium_low = dataset[split_low,divideDim]\n",
    "                            break\n",
    "                \n",
    "                if query_bound[divideDim][i][1] < domains[divideDim][1]:\n",
    "                # get the number of records from medium to the end\n",
    "                    for j in range(split_position,total_size,1):\n",
    "                        if dataset[j][divideDim] >= query_bound[divideDim][i][1]:\n",
    "                            split_up = j\n",
    "                            medium_up = dataset[split_up,divideDim]\n",
    "                            break\n",
    "                \n",
    "            # if not exceeds then choose the one that is closest from the medium (in terms of #records!)\n",
    "            if (total_size/2) - split_low < (split_up - total_size/2) and split_low != 0:\n",
    "                split_position = split_low\n",
    "                medium = medium_low\n",
    "            elif (total_size/2) - split_low >= (split_up - total_size/2) and split_up != total_size :\n",
    "                split_position = split_up\n",
    "                medium = medium_up\n",
    "            \n",
    "            # after handle the overlap bounding, we can skip the remaining, as there will be at most 1 as assumned\n",
    "            break;\n",
    "            \n",
    "    # split the dataset according to the split position\n",
    "    sub_dataset1 = dataset[0:split_position,:]\n",
    "    sub_dataset2 = dataset[split_position:-1,:]\n",
    "    \n",
    "    # change the domains\n",
    "    sub_domains1 = np.copy(domains)\n",
    "    sub_domains1[divideDim][1] = medium\n",
    "    sub_domains2 = np.copy(domains)\n",
    "    sub_domains2[divideDim][0] = medium\n",
    "    \n",
    "    # change the divideDim\n",
    "    currentDim += 1\n",
    "    if currentDim >= len(Dimorder):\n",
    "        currentDim %= len(Dimorder)\n",
    "    \n",
    "    # used to see the current depth\n",
    "    level += 1\n",
    "    \n",
    "    # recursion\n",
    "    kdnodes = []\n",
    "    kdnodes.extend(ResuriveDivide(sub_dataset1, query_bound, currentDim, Dimorder, sub_domains1, threshold, level))\n",
    "    kdnodes.extend(ResuriveDivide(sub_dataset2, query_bound, currentDim, Dimorder, sub_domains2, threshold, level))\n",
    "    \n",
    "    # print(\"kdnodes: \",len(kdnodes))\n",
    "    \n",
    "    return kdnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_ = [\\\n",
    "    [1,1.20000000e+07],\\\n",
    "    [1,4.00000000e+05],\\\n",
    "    [1,2.00000000e+04],\\\n",
    "    [1,7.00000000e+00],\\\n",
    "    [1,5.00000000e+01],\\\n",
    "    [900.99,1.04899500e+05],\\\n",
    "    [0,1.00000000e-01],\\\n",
    "    [0,8.00000000e-02]\\\n",
    "] \n",
    "\n",
    "dataset = genfromtxt('/Users/lizhe/Desktop/LearnedKDTree/DataAndWorkload/SyntheticData/TPCH_12M_8Field.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n"
     ]
    }
   ],
   "source": [
    "# Example of usage (Learned KD-Tree Split)\n",
    "#\n",
    "def CallToLearnedKDTree(dataset, Dimorder_, domains_, bounded_queries, threshold):\n",
    "    dataset = dataset[:,Dimorder_] # retrieve only the used dimension, auto ordered into the Dimorder way\n",
    "    domains_ = np.asarray(domains_)\n",
    "    domains_ = domains_[Dimorder_]\n",
    "    bounded_queries = np.asarray(bounded_queries)\n",
    "    bounded_queries = bounded_queries[Dimorder_]\n",
    "    \n",
    "    kdnodes = ResuriveDivide(dataset, bounded_queries, 0, Dimorder_, domains_, threshold, 0)\n",
    "    print(len(kdnodes))\n",
    "    return kdnodes\n",
    " \n",
    "Dimorder_ = [1,0] # should be the dimensions that is already bounded before\n",
    "\n",
    "kdnodes = CallToLearnedKDTree(dataset, Dimorder_, domains_, bounded_queries, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Performance Evaluation ===\n",
    "#\n",
    "# evaluate the blocks of data to be fetched, when physical data of kdnodes are seperate !!!\n",
    "# @queries: a collection of queries contains the lower and upper value in all dimensions; numpy object\n",
    "# @kdnodes: the kdnodes generated above; array object\n",
    "#\n",
    "def Query(queries, kdnodes):\n",
    "    \n",
    "    counts = []\n",
    "    count_single_query = 0;\n",
    "    \n",
    "    # number of dimensions\n",
    "    dims = int(len(queries[0])/2)\n",
    "    \n",
    "    # for each query\n",
    "    for i in range(len(queries)):\n",
    "        \n",
    "        count_single_query = 0\n",
    "        \n",
    "        # check for intersection for each kdnode\n",
    "        for j in range(len(kdnodes)):\n",
    "            \n",
    "            # for each dimension\n",
    "            intersection_tag = True\n",
    "            for k in range(dims):\n",
    "                \n",
    "                # an intersection holds if it intersecs in all dimensions\n",
    "                if queries[i][2*k] >= kdnodes[j][0][k][1] or queries[i][2*k+1] <= kdnodes[j][0][k][0]:\n",
    "                    intersection_tag = False\n",
    "                    break\n",
    "                \n",
    "            # if the query intersect with this kdnode\n",
    "            if intersection_tag:\n",
    "                count_single_query += 1\n",
    "            \n",
    "        counts.append(count_single_query)\n",
    "    \n",
    "    print(\"blocks IO: \", counts)\n",
    "    print(\"blocks IO(average): \", statistics.mean(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks IO:  [1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n",
      "blocks IO(average):  1.0940940940940942\n"
     ]
    }
   ],
   "source": [
    "# Example of usage (Performance Evaluation)\n",
    "#\n",
    "query_order = []\n",
    "for i in range(len(Dimorder_)):\n",
    "    query_order.append(2*Dimorder_[i])\n",
    "    query_order.append(2*Dimorder_[i]+1)\n",
    "learned_testing_set = np.copy(testing_set)\n",
    "learned_testing_set = learned_testing_set[:,query_order]\n",
    "\n",
    "Query(learned_testing_set, kdnodes) # the queries generated in Query Bounding use 10% of the generated queries, should be in Dimorder order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Physical Storage ===\n",
    "#\n",
    "# Reform the kdnodes from seperate physcial stroage to dense, continous physical storage\n",
    "#\n",
    "# @kdnodes: the previous generated kdnodes, already in order; array\n",
    "# @threshold: the maximum page size \n",
    "#\n",
    "# return @dense_kdnodes: array\n",
    "#\n",
    "def DenseKDNodes(kdnodes, threshold):\n",
    "    \n",
    "    dense_kdnodes = []\n",
    "    previous_records = 0\n",
    "    current_records = 0\n",
    "    page_count = 0\n",
    "    \n",
    "    for i in range(len(kdnodes)):\n",
    "        previous_records = current_records\n",
    "        current_records += kdnodes[i][1]\n",
    "        if current_records > threshold:\n",
    "            # determine how many pages exceeds\n",
    "            remaining = kdnodes[i][1] - (threshold - previous_records)\n",
    "            num_pages = math.ceil(remaining / threshold) # num of new pages required\n",
    "            pages = [i+page_count for i in range(num_pages+1)]\n",
    "            page_count += num_pages\n",
    "            current_records = remaining % threshold\n",
    "            dense_kdn = [kdnodes[i][0],pages]\n",
    "            dense_kdnodes.append(dense_kdn)\n",
    "        else:\n",
    "            dense_kdn = [kdnodes[i][0],[page_count]]\n",
    "            dense_kdnodes.append(dense_kdn)\n",
    "                         \n",
    "    return dense_kdnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of usage (Physical Storage)\n",
    "#\n",
    "dense_kdnodes = DenseKDNodes(kdnodes, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Performance Evaluation (dense) ===\n",
    "#\n",
    "# evaluate the blocks of data to be fetched, when physical data of kdnodes are dense !!!\n",
    "# @queries: a collection of queries contains the lower and upper value in all dimensions; numpy object\n",
    "# @kdnodes: the kdnodes generated above; array object\n",
    "#\n",
    "def QueryDense(queries, dense_kdnodes):\n",
    "    \n",
    "    counts = []\n",
    "    count_single_query = 0;\n",
    "    \n",
    "    # number of dimensions\n",
    "    dims = int(len(queries[0])/2)\n",
    "    \n",
    "    # for each query\n",
    "    for i in range(len(queries)):\n",
    "        \n",
    "        pages = []\n",
    "        \n",
    "        # check for intersection for each kdnode\n",
    "        for j in range(len(dense_kdnodes)):\n",
    "            \n",
    "            # for each dimension\n",
    "            intersection_tag = True\n",
    "            for k in range(dims):\n",
    "                \n",
    "                # an intersection holds if it intersecs in all dimensions\n",
    "                if queries[i][2*k] >= dense_kdnodes[j][0][k][1] or queries[i][2*k+1] <= dense_kdnodes[j][0][k][0]:\n",
    "                    intersection_tag = False\n",
    "                    break\n",
    "                \n",
    "            # if the query intersect with this kdnode\n",
    "            if intersection_tag:\n",
    "                pages.extend(dense_kdnodes[j][1]) # remember to remove repeated\n",
    "        \n",
    "        counts.append(len(set(pages)))\n",
    "    \n",
    "    print(\"blocks IO: \", counts)\n",
    "    print(\"blocks IO(average): \", statistics.mean(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks IO:  [2, 1, 2, 1, 2, 2, 2, 2, 3, 2, 1, 2, 4, 3, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 4, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 3, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 1, 1, 1, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 3, 2, 2, 4, 2, 1, 1, 3, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 3, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 1, 1, 2, 3, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 3, 4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 4, 2, 2, 1, 1, 2, 2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 1, 1, 2, 3, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 3, 2, 2, 2, 3, 4, 2, 1, 4, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 1, 2, 2, 2, 3, 1, 3, 2, 2, 3, 2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 4, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 4, 1, 4, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 3, 2, 2, 3, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 3, 2, 1, 2, 2, 2, 3, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 3, 2, 2, 1, 1, 4, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 3, 2, 2, 2, 2, 2, 1, 2, 4, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 4, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 4, 2, 2, 1, 2, 2, 2, 4, 3, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 3, 2, 1, 1, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 3]\n",
      "blocks IO(average):  1.8198198198198199\n"
     ]
    }
   ],
   "source": [
    "# Example of usage (Performance Evaluation (dense))\n",
    "#\n",
    "QueryDense(learned_testing_set, dense_kdnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compare With Existing === \n",
    "#\n",
    "# TraditionalKDTree (sparse)\n",
    "# The parameters are just like the learned kdtree\n",
    "#\n",
    "# return: so is the return\n",
    "#\n",
    "def TraditionalKDTree(dataset, currentDim, Dimorder, domains, threshold, level):\n",
    "    \n",
    "    #print(\"level: \",level)\n",
    "    #print(\"dataset size: \",len(dataset))\n",
    "    \n",
    "    # check if the threshold is already satisfied\n",
    "    total_size = len(dataset)\n",
    "    if total_size <= threshold:\n",
    "        # the kdnodes should be an global object outside the function\n",
    "        kdnodes = []\n",
    "        kdnodes.append([domains,total_size])\n",
    "        return kdnodes\n",
    "    \n",
    "    # the current dimension\n",
    "    # divideDim = Dimorder[currentDim]\n",
    "    divideDim = currentDim # the dataset is already ordered as the Dimorder\n",
    "    \n",
    "    # sort according to the current dimension\n",
    "    dataset = dataset[dataset[:,divideDim].argsort()]\n",
    "    \n",
    "    # find the medium\n",
    "    medium = dataset[int(total_size/2),divideDim]\n",
    "\n",
    "    # start check split position from the medium\n",
    "    split_position = int(total_size/2)\n",
    "            \n",
    "    # split the dataset according to the split position\n",
    "    sub_dataset1 = dataset[0:split_position,:]\n",
    "    sub_dataset2 = dataset[split_position:-1,:]\n",
    "    \n",
    "    # change the domains\n",
    "    sub_domains1 = np.copy(domains)\n",
    "    sub_domains1[divideDim][1] = medium\n",
    "    sub_domains2 = np.copy(domains)\n",
    "    sub_domains2[divideDim][0] = medium\n",
    "    \n",
    "    # change the divideDim\n",
    "    currentDim += 1\n",
    "    if currentDim >= len(Dimorder):\n",
    "        currentDim %= len(Dimorder)\n",
    "    \n",
    "    # used to see the current depth\n",
    "    level += 1\n",
    "    \n",
    "    # recursion\n",
    "    kdnodes = []\n",
    "    kdnodes.extend(TraditionalKDTree(sub_dataset1, currentDim, Dimorder, sub_domains1, threshold, level))\n",
    "    kdnodes.extend(TraditionalKDTree(sub_dataset2, currentDim, Dimorder, sub_domains2, threshold, level))\n",
    "    \n",
    "    return kdnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "# Example of usage (Compare With Existing)\n",
    "#\n",
    "def CallToTradKDTree(dataset, Dimorder_, domains_, threshold):\n",
    "    dataset = dataset[:,Dimorder_] # retrieve only the used dimension, auto ordered into the Dimorder way\n",
    "    domains_ = np.asarray(domains_)\n",
    "    domains_ = domains_[Dimorder_]\n",
    "    \n",
    "    kdnodes = TraditionalKDTree(dataset, 0, trad_Dimorder_, domains_, threshold, 0)\n",
    "    print(len(kdnodes))\n",
    "    return kdnodes\n",
    " \n",
    "trad_Dimorder_ = [1,0]\n",
    "\n",
    "traditional_kdnodes = CallToTradKDTree(dataset, trad_Dimorder_, domains_, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks IO:  [1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n",
      "blocks IO(average):  1.097097097097097\n"
     ]
    }
   ],
   "source": [
    "query_order = []\n",
    "for i in range(len(trad_Dimorder_)):\n",
    "    query_order.append(2*trad_Dimorder_[i])\n",
    "    query_order.append(2*trad_Dimorder_[i]+1)\n",
    "trad_testing_set = np.copy(testing_set)\n",
    "trad_testing_set = trad_testing_set[:,query_order]\n",
    "Query(trad_testing_set, traditional_kdnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks IO:  [2, 2, 2, 1, 3, 2, 2, 2, 2, 4, 2, 2, 4, 3, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 4, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 3, 2, 1, 2, 1, 4, 2, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 4, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 3, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 1, 2, 2, 2, 2, 1, 2, 3, 2, 1, 2, 3, 2, 2, 2, 1, 2, 2, 2, 1, 2, 3, 2, 2, 1, 2, 2, 1, 3, 2, 2, 1, 2, 3, 1, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 2, 2, 2, 1, 3, 2, 2, 2, 1, 2, 2, 2, 1, 2, 4, 2, 1, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 1, 4, 1, 2, 2, 1, 1, 2, 1, 2, 2, 3, 2, 4, 2, 1, 1, 2, 1, 2, 2, 2, 1, 4, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 4, 3, 2, 1, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 4, 2, 1, 2, 1, 1, 1, 2, 2, 4, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 4, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 3, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 4, 1, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 4, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 3, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 4, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 4, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 4, 2, 1, 2, 1, 2, 1, 1, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 4, 2, 4, 2, 2, 2, 1, 2, 1, 2, 2, 3, 2, 4, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 3, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 3, 1, 2, 2, 1, 2, 2, 4, 4, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 4, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 3]\n",
      "blocks IO(average):  1.8758758758758758\n"
     ]
    }
   ],
   "source": [
    "dense_traditional_kdnodes = DenseKDNodes(traditional_kdnodes, 32000)\n",
    "QueryDense(trad_testing_set, dense_traditional_kdnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
